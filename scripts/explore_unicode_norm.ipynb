{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode Normalization and Search Anchor Analysis\n",
    "\n",
    "This notebook explores Unicode case folding and normalization properties to identify optimal \"anchor points\" for case-insensitive and normalization-insensitive string search algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -q pandas 2>/dev/null || curl -sS https://bootstrap.pypa.io/get-pip.py | python && python -m pip install -q pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before we start, a small reminder on Unicode.\n",
    "Unicode is a versioned standard.\n",
    "In 2025, the latest version is Unicode 17.0.\n",
    "It defines over a million code points, of which around 150,000 are assigned characters.\n",
    "Some of them belong to \"bicameral\" scripts (like Latin, Greek, Cyrillic) that have distinct uppercase and lowercase forms.\n",
    "Others belong to \"unicameral\" scripts (like Chinese, Japanese, Korean, Arabic) that do not have case distinctions.\n",
    "It doesn't, however, mean that there are no different ways to represent the same character in the same script.\n",
    "So \"case folding\" and \"normalization\" are two different concepts.\n",
    "We will explore both in this notebook.\n",
    "\n",
    "Unicode also doesn't require UTF-8 encoding, but UTF-8 is the most popular encoding on the web and in modern applications and the one we will focus on in StringZilla.\n",
    "In UTF-8, each code point is represented by one, two, three, or four bytes.\n",
    "A folded or normalized character can map to a sequence of multiple code points, and each of those code points can have a different length representation in UTF-8.\n",
    "That's why, in the absolute majority of modern text-processing applications full Unicode processing is disabled.\n",
    "\n",
    "Typically, when people perform case-insensitive search, they either:\n",
    "\n",
    "1. Use simple ASCII case folding (A-Z to a-z), ignoring all other characters.\n",
    "2. Use pretty much the only major library that supports full Unicode case folding and normalization, ICU (International Components for Unicode).\n",
    "\n",
    "The first is clearly insufficient, and the second is quite heavy and works at a character level, making SIMD optimizations difficult.\n",
    "This notebook will focus on more SIMD-vectorizable ideas.\n",
    "\n",
    "To start, let's pull the most recent Unicode Character Database (UCD) files from the Unicode website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Unicode version: 17.0.0\n",
      "Using cached Unicode 17.0.0 UCD XML: /tmp/ucd-17.0.0.all.flat.xml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "# Import shared Unicode data loading functions\n",
    "sys.path.insert(0, \".\")\n",
    "from test_helpers import (\n",
    "    UNICODE_VERSION,\n",
    "    get_all_codepoints,\n",
    "    get_case_folding_rules_as_codepoints,\n",
    "    get_normalization_props,\n",
    "    get_unicode_xml_data,\n",
    ")\n",
    "\n",
    "# UTF-8 byte boundaries\n",
    "UTF8_1BYTE_MAX = 0x7F  # 127 - ASCII range\n",
    "UTF8_2BYTE_MAX = 0x7FF  # 2047\n",
    "UTF8_3BYTE_MAX = 0xFFFF  # 65535\n",
    "\n",
    "print(f\"Using Unicode version: {UNICODE_VERSION}\")\n",
    "all_codepoints = get_all_codepoints(UNICODE_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The highest allowed code point in Unicode is `0x10FFFF` or \"U+10FFFF\"](https://stackoverflow.com/questions/52203351/why-is-unicode-restricted-to-0x10ffff), but it doesn't mean that all code points up to that value are assigned.\n",
    "\n",
    "- Planes 15-16 (U+F0000 to U+10FFFF) are reserved for \"Private Use Area\" and do not contain assigned characters.\n",
    "- Most of plane 14 (U+E0000 to U+E0FFF) is reserved for \"Supplementary Special-purpose Plane\" and contains very few assigned characters.\n",
    "- Many code points in other planes are also unassigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total assigned codepoints: 159,866\n",
      "Highest assigned codepoint: 917,999\n",
      "Highest possible codepoint: 1,114,111\n",
      "Range density: 17.414597%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total assigned codepoints: {len(all_codepoints):,}\")\n",
    "print(f\"Highest assigned codepoint: {all_codepoints[-1]:,}\")\n",
    "print(f\"Highest possible codepoint: {0x10FFFF:,}\")\n",
    "print(f\"Range density: {len(all_codepoints) / (all_codepoints[-1] + 1):.6%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode Case Folding Analysis\n",
    "\n",
    "### Direct Folding Targets\n",
    "\n",
    "Case folding maps characters to a \"folded\" form for case-insensitive comparisons.\n",
    "This is more comprehensive than simple lowercasing - it handles special cases like German √ü ‚Üí ss.\n",
    "The very first thing we are interested in is: how often each codepoint becomes a folding target for other characters?\n",
    "\n",
    "The reason we are curious about this is that in simple cases, like the Russian letter \"–ê\" (A) and \"–∞\" (a), both fold to the same codepoint U+0430 (Cyrillic small letter a).\n",
    "So when scanning for exact case-insensitive matches, we can just compare each 2-byte UTF-8 slice against just 2 possible values: 0xD090 (U+0410) and 0xD0B0 (U+0430), without actually performing any case folding.\n",
    "The easiest way to solve the problem is to avoid it after all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached Unicode 17.0.0 CaseFolding.txt: /tmp/CaseFolding-17.0.0.txt\n",
      "Total case folding rules: 1,585\n"
     ]
    }
   ],
   "source": [
    "case_folds = get_case_folding_rules_as_codepoints(UNICODE_VERSION)\n",
    "print(f\"Total case folding rules: {len(case_folds):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total folding rules: 1,705\n",
      "Unique target codepoints: 1,462\n"
     ]
    }
   ],
   "source": [
    "target_frequency = Counter()\n",
    "\n",
    "for source_codepoint, target_codepoints in case_folds.items():\n",
    "    for target_codepoint in target_codepoints:\n",
    "        target_frequency[target_codepoint] += 1\n",
    "\n",
    "print(f\"Total folding rules: {sum(target_frequency.values()):,}\")\n",
    "print(f\"Unique target codepoints: {len(target_frequency):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the most common folding targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codepoint</th>\n",
       "      <th>Char</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U+03B9</td>\n",
       "      <td>Œπ</td>\n",
       "      <td>71</td>\n",
       "      <td>GREEK SMALL LETTER IOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U+0342</td>\n",
       "      <td>ÕÇ</td>\n",
       "      <td>11</td>\n",
       "      <td>COMBINING GREEK PERISPOMENI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U+03C5</td>\n",
       "      <td>œÖ</td>\n",
       "      <td>10</td>\n",
       "      <td>GREEK SMALL LETTER UPSILON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U+0066</td>\n",
       "      <td>f</td>\n",
       "      <td>9</td>\n",
       "      <td>LATIN SMALL LETTER F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U+0308</td>\n",
       "      <td>Ãà</td>\n",
       "      <td>9</td>\n",
       "      <td>COMBINING DIAERESIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>U+1E93F</td>\n",
       "      <td>û§ø</td>\n",
       "      <td>1</td>\n",
       "      <td>ADLAM SMALL LETTER KHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>U+1E940</td>\n",
       "      <td>û•Ä</td>\n",
       "      <td>1</td>\n",
       "      <td>ADLAM SMALL LETTER GBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>U+1E941</td>\n",
       "      <td>û•Å</td>\n",
       "      <td>1</td>\n",
       "      <td>ADLAM SMALL LETTER ZAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>U+1E942</td>\n",
       "      <td>û•Ç</td>\n",
       "      <td>1</td>\n",
       "      <td>ADLAM SMALL LETTER KPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>U+1E943</td>\n",
       "      <td>û•É</td>\n",
       "      <td>1</td>\n",
       "      <td>ADLAM SMALL LETTER SHA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Codepoint Char  Frequency                         Name\n",
       "0       U+03B9    Œπ         71      GREEK SMALL LETTER IOTA\n",
       "1       U+0342    ÕÇ         11  COMBINING GREEK PERISPOMENI\n",
       "2       U+03C5    œÖ         10   GREEK SMALL LETTER UPSILON\n",
       "3       U+0066    f          9         LATIN SMALL LETTER F\n",
       "4       U+0308    Ãà          9          COMBINING DIAERESIS\n",
       "...        ...  ...        ...                          ...\n",
       "1457   U+1E93F    û§ø          1       ADLAM SMALL LETTER KHA\n",
       "1458   U+1E940    û•Ä          1       ADLAM SMALL LETTER GBE\n",
       "1459   U+1E941    û•Å          1       ADLAM SMALL LETTER ZAL\n",
       "1460   U+1E942    û•Ç          1       ADLAM SMALL LETTER KPO\n",
       "1461   U+1E943    û•É          1       ADLAM SMALL LETTER SHA\n",
       "\n",
       "[1462 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for codepoint, frequency in target_frequency.most_common():\n",
    "    try:\n",
    "        character = chr(codepoint)\n",
    "        name = unicodedata.name(character, \"\")\n",
    "    except (ValueError, OverflowError):\n",
    "        character = \"?\"\n",
    "        name = \"\"\n",
    "    rows.append({\"Codepoint\": f\"U+{codepoint:04X}\", \"Char\": character, \"Frequency\": frequency, \"Name\": name})\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that the \"GREEK SMALL LETTER IOTA\" (U+03B9) is the most common folding target, being the folded form of 71 different codepoints.\n",
    "The reason for this is historical.\n",
    "Ancient Greek had a grammatical feature called the \"iota subscript\" where iota was written as a small subscript beneath vowels (Œ±, Œ∑, œâ) to indicate certain grammatical forms (dative case, etc.).\n",
    "When case-folding, these decompose and the subscript iota becomes a regular lowercase iota:\n",
    "\n",
    "- ·æ≥ (alpha with ypogegrammeni) ‚Üí Œ±Œπ\n",
    "- ·øÉ (eta with ypogegrammeni) ‚Üí Œ∑Œπ\n",
    "- ·ø≥ (omega with ypogegrammeni) ‚Üí œâŒπ\n",
    "\n",
    "More importantly, at this point we see that `'f'`, `'s'`, `'i'`, `'t'` are the most common direct single-byte UTF-8 folding targets.\n",
    "Each is the target of at least 4 different codepoints.\n",
    "But that doesn't tell the whole story!\n",
    "\n",
    "### Otherwise Ambiguous Folding Targets\n",
    "\n",
    "Oftentimes, a character is only one of many characters in the produced folding result.\n",
    "\n",
    "- `'Ô¨Ä'` ‚Üí `\"ff\"` - 3-byte codepoint mapping into 2x 1-byte codepoints\n",
    "- `'Ô¨Å'` ‚Üí `\"fi\"` - 3-byte codepoint mapping into 2x 1-byte codepoints\n",
    "- `'Ô¨Ç'` ‚Üí `\"fl\"` - 3-byte codepoint mapping into 2x 1-byte codepoints\n",
    "- `'Ô¨É'` ‚Üí `\"ffi\"` - 3-byte codepoint mapping into 3x 1-byte codepoints\n",
    "- `'Ô¨Ñ'` ‚Üí `\"ffl\"` - 3-byte codepoint mapping into 3x 1-byte codepoints\n",
    "\n",
    "Let's account for those as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total folding rules: 1,585\n",
      "  - Direct 1:1 foldings: 1,481\n",
      "  - Multi-codepoint expansions: 104\n",
      "\n",
      "Unique target codepoints:\n",
      "  - Only direct targets: 1,398\n",
      "  - Only partial targets: 48\n",
      "  - Both direct AND partial: 54\n"
     ]
    }
   ],
   "source": [
    "direct_target_frequency = Counter()  # Codepoint is the ONLY target of a folding\n",
    "partial_target_frequency = Counter()  # Codepoint is ONE OF multiple targets in a folding\n",
    "\n",
    "for source_codepoint, target_codepoints in case_folds.items():\n",
    "    if len(target_codepoints) == 1:\n",
    "        # Direct 1:1 folding (e.g., 'A' ‚Üí 'a')\n",
    "        direct_target_frequency[target_codepoints[0]] += 1\n",
    "    else:\n",
    "        # Multi-codepoint expansion (e.g., 'Ô¨Å' ‚Üí 'f', 'i')\n",
    "        for target_codepoint in target_codepoints:\n",
    "            partial_target_frequency[target_codepoint] += 1\n",
    "\n",
    "# Some codepoints may be both direct AND partial targets\n",
    "both_targets = set(direct_target_frequency.keys()) & set(partial_target_frequency.keys())\n",
    "\n",
    "print(f\"Total folding rules: {len(case_folds):,}\")\n",
    "print(f\"  - Direct 1:1 foldings: {sum(1 for t in case_folds.values() if len(t) == 1):,}\")\n",
    "print(f\"  - Multi-codepoint expansions: {sum(1 for t in case_folds.values() if len(t) > 1):,}\")\n",
    "print()\n",
    "print(f\"Unique target codepoints:\")\n",
    "print(f\"  - Only direct targets: {len(direct_target_frequency - partial_target_frequency):,}\")\n",
    "print(f\"  - Only partial targets: {len(partial_target_frequency - direct_target_frequency):,}\")\n",
    "print(f\"  - Both direct AND partial: {len(both_targets):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table differentiates complete and partial folding targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codepoint</th>\n",
       "      <th>Char</th>\n",
       "      <th>Partial</th>\n",
       "      <th>Direct</th>\n",
       "      <th>Example Expansion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U+03B9</td>\n",
       "      <td>Œπ</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>'Œê' ‚Üí \"ŒπÃàÃÅ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U+0342</td>\n",
       "      <td>ÕÇ</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>'·Ωñ' ‚Üí \"œÖÃìÕÇ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U+0308</td>\n",
       "      <td>Ãà</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>'Œê' ‚Üí \"ŒπÃàÃÅ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U+03C5</td>\n",
       "      <td>œÖ</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>'Œ∞' ‚Üí \"œÖÃàÃÅ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U+0066</td>\n",
       "      <td>f</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>'Ô¨Ä' ‚Üí \"ff\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>U+1F7C</td>\n",
       "      <td>·Ωº</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'·ø≤' ‚Üí \"·ΩºŒπ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>U+03CE</td>\n",
       "      <td>œé</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'·ø¥' ‚Üí \"œéŒπ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>U+056B</td>\n",
       "      <td>’´</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Ô¨ï' ‚Üí \"’¥’´\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>U+057E</td>\n",
       "      <td>’æ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Ô¨ñ' ‚Üí \"’æ’∂\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>U+056D</td>\n",
       "      <td>’≠</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'Ô¨ó' ‚Üí \"’¥’≠\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Codepoint Char  Partial  Direct Example Expansion\n",
       "0     U+03B9    Œπ       68       3       'Œê' ‚Üí \"ŒπÃàÃÅ\"\n",
       "1     U+0342    ÕÇ       11       0       '·Ωñ' ‚Üí \"œÖÃìÕÇ\"\n",
       "2     U+0308    Ãà        9       0       'Œê' ‚Üí \"ŒπÃàÃÅ\"\n",
       "3     U+03C5    œÖ        9       1       'Œ∞' ‚Üí \"œÖÃàÃÅ\"\n",
       "4     U+0066    f        8       1        'Ô¨Ä' ‚Üí \"ff\"\n",
       "..       ...  ...      ...     ...               ...\n",
       "60    U+1F7C    ·Ωº        1       1        '·ø≤' ‚Üí \"·ΩºŒπ\"\n",
       "61    U+03CE    œé        1       1        '·ø¥' ‚Üí \"œéŒπ\"\n",
       "62    U+056B    ’´        1       1        'Ô¨ï' ‚Üí \"’¥’´\"\n",
       "63    U+057E    ’æ        1       1        'Ô¨ñ' ‚Üí \"’æ’∂\"\n",
       "64    U+056D    ’≠        1       1        'Ô¨ó' ‚Üí \"’¥’≠\"\n",
       "\n",
       "[65 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for codepoint, partial_frequency in partial_target_frequency.most_common():\n",
    "    try:\n",
    "        character = chr(codepoint)\n",
    "    except (ValueError, OverflowError):\n",
    "        character = \"?\"\n",
    "\n",
    "    direct_frequency = direct_target_frequency.get(codepoint, 0)\n",
    "\n",
    "    # Find an example expansion containing this codepoint\n",
    "    example = \"\"\n",
    "    for source_codepoint, target_codepoints in case_folds.items():\n",
    "        if len(target_codepoints) > 1 and codepoint in target_codepoints:\n",
    "            try:\n",
    "                source_character = chr(source_codepoint)\n",
    "                target_string = \"\".join(chr(c) for c in target_codepoints)\n",
    "                example = f\"'{source_character}' ‚Üí \\\"{target_string}\\\"\"\n",
    "            except (ValueError, OverflowError):\n",
    "                example = f\"U+{source_codepoint:04X} ‚Üí {target_codepoints}\"\n",
    "            break\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"Codepoint\": f\"U+{codepoint:04X}\",\n",
    "            \"Char\": character,\n",
    "            \"Partial\": partial_frequency,\n",
    "            \"Direct\": direct_frequency,\n",
    "            \"Example Expansion\": example,\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safe Single-byte Folding Anchors\n",
    "\n",
    "Of all those characters, we are most interested in the codepoints representable in just 1 byte in UTF-8, as we can process 64 of them in a `ZMM` register at once.\n",
    "Those are the boring ASCII letters.\n",
    "But we can't just apply traditional SIMD ASCII case-insensitive search techniques like:\n",
    "\n",
    "```c\n",
    "__m512i lower_mask = _mm512_set1_epi8(0x20);\n",
    "__m512i input_chunk = _mm512_loadu_si512(input_ptr);\n",
    "__m512i folded_chunk = _mm512_or_si512(input_chunk, lower_mask);\n",
    "```\n",
    "\n",
    "If the needle contains an `'f'` and the haystack contains an `'Ô¨É'`, we would miss the match.\n",
    "So we must know, which of the single-byte codepoints are folding targets of multiple codepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ASCII targets: 26\n",
      "  - Safe (exactly 1 source): 14\n",
      "  - Ambiguous (multiple sources): 12\n"
     ]
    }
   ],
   "source": [
    "ascii_targets = {}\n",
    "for codepoint in range(UTF8_1BYTE_MAX + 1):\n",
    "    direct = direct_target_frequency.get(codepoint, 0)\n",
    "    partial = partial_target_frequency.get(codepoint, 0)\n",
    "    total = direct + partial\n",
    "    if total > 0:\n",
    "        ascii_targets[codepoint] = {\"direct\": direct, \"partial\": partial, \"total\": total}\n",
    "\n",
    "# Separate into \"safe\" (exactly 1 source) vs \"ambiguous\" (multiple sources)\n",
    "safe_ascii = {codepoint: info for codepoint, info in ascii_targets.items() if info[\"total\"] == 1}\n",
    "ambiguous_ascii = {codepoint: info for codepoint, info in ascii_targets.items() if info[\"total\"] > 1}\n",
    "\n",
    "print(f\"Total ASCII targets: {len(ascii_targets)}\")\n",
    "print(f\"  - Safe (exactly 1 source): {len(safe_ascii)}\")\n",
    "print(f\"  - Ambiguous (multiple sources): {len(ambiguous_ascii)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows safe ASCII targets that can use simple SIMD case folding (each has exactly one source):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'b' (U+0062)</td>\n",
       "      <td>'B' (U+0042)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'c' (U+0063)</td>\n",
       "      <td>'C' (U+0043)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'d' (U+0064)</td>\n",
       "      <td>'D' (U+0044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'e' (U+0065)</td>\n",
       "      <td>'E' (U+0045)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'g' (U+0067)</td>\n",
       "      <td>'G' (U+0047)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'m' (U+006D)</td>\n",
       "      <td>'M' (U+004D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'o' (U+006F)</td>\n",
       "      <td>'O' (U+004F)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'p' (U+0070)</td>\n",
       "      <td>'P' (U+0050)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'q' (U+0071)</td>\n",
       "      <td>'Q' (U+0051)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'r' (U+0072)</td>\n",
       "      <td>'R' (U+0052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'u' (U+0075)</td>\n",
       "      <td>'U' (U+0055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'v' (U+0076)</td>\n",
       "      <td>'V' (U+0056)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'x' (U+0078)</td>\n",
       "      <td>'X' (U+0058)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'z' (U+007A)</td>\n",
       "      <td>'Z' (U+005A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Target        Source\n",
       "0   'b' (U+0062)  'B' (U+0042)\n",
       "1   'c' (U+0063)  'C' (U+0043)\n",
       "2   'd' (U+0064)  'D' (U+0044)\n",
       "3   'e' (U+0065)  'E' (U+0045)\n",
       "4   'g' (U+0067)  'G' (U+0047)\n",
       "5   'm' (U+006D)  'M' (U+004D)\n",
       "6   'o' (U+006F)  'O' (U+004F)\n",
       "7   'p' (U+0070)  'P' (U+0050)\n",
       "8   'q' (U+0071)  'Q' (U+0051)\n",
       "9   'r' (U+0072)  'R' (U+0052)\n",
       "10  'u' (U+0075)  'U' (U+0055)\n",
       "11  'v' (U+0076)  'V' (U+0056)\n",
       "12  'x' (U+0078)  'X' (U+0058)\n",
       "13  'z' (U+007A)  'Z' (U+005A)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_rows = []\n",
    "for codepoint in sorted(safe_ascii.keys()):\n",
    "    character = chr(codepoint)\n",
    "    for source_codepoint, target_codepoints in case_folds.items():\n",
    "        if codepoint in target_codepoints:\n",
    "            source_character = chr(source_codepoint)\n",
    "            safe_rows.append(\n",
    "                {\n",
    "                    \"Target\": f\"'{character}' (U+{codepoint:04X})\",\n",
    "                    \"Source\": f\"'{source_character}' (U+{source_codepoint:04X})\",\n",
    "                }\n",
    "            )\n",
    "            break\n",
    "\n",
    "pd.DataFrame(safe_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows ambiguous ASCII targets that need special handling in SIMD (each has multiple sources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Char</th>\n",
       "      <th>Codepoint</th>\n",
       "      <th>Direct</th>\n",
       "      <th>Partial</th>\n",
       "      <th>Total</th>\n",
       "      <th>Sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'a'</td>\n",
       "      <td>U+0061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>'A', '·∫ö'‚Üí\"a æ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'f'</td>\n",
       "      <td>U+0066</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>'F', 'Ô¨Ä'‚Üí\"ff\", 'Ô¨Å'‚Üí\"fi\", 'Ô¨Ç'‚Üí\"fl\", 'Ô¨É'‚Üí\"ffi\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'h'</td>\n",
       "      <td>U+0068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>'H', '·∫ñ'‚Üí\"hÃ±\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'i'</td>\n",
       "      <td>U+0069</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>'I', 'ƒ∞'‚Üí\"iÃá\", 'Ô¨Å'‚Üí\"fi\", 'Ô¨É'‚Üí\"ffi\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'j'</td>\n",
       "      <td>U+006A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>'J', '«∞'‚Üí\"jÃå\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'k'</td>\n",
       "      <td>U+006B</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>'K', '‚Ñ™'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'l'</td>\n",
       "      <td>U+006C</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>'L', 'Ô¨Ç'‚Üí\"fl\", 'Ô¨Ñ'‚Üí\"ffl\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'n'</td>\n",
       "      <td>U+006E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>'N', '≈â'‚Üí\" ºn\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'s'</td>\n",
       "      <td>U+0073</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>'S', '√ü'‚Üí\"ss\", '≈ø', '·∫û'‚Üí\"ss\", 'Ô¨Ö'‚Üí\"st\", 'Ô¨Ü'‚Üí\"st\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'t'</td>\n",
       "      <td>U+0074</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>'T', '·∫ó'‚Üí\"tÃà\", 'Ô¨Ö'‚Üí\"st\", 'Ô¨Ü'‚Üí\"st\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'w'</td>\n",
       "      <td>U+0077</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>'W', '·∫ò'‚Üí\"wÃä\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'y'</td>\n",
       "      <td>U+0079</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>'Y', '·∫ô'‚Üí\"yÃä\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Char Codepoint  Direct  Partial  Total  \\\n",
       "0   'a'    U+0061       1        1      2   \n",
       "1   'f'    U+0066       1        8      9   \n",
       "2   'h'    U+0068       1        1      2   \n",
       "3   'i'    U+0069       1        3      4   \n",
       "4   'j'    U+006A       1        1      2   \n",
       "5   'k'    U+006B       2        0      2   \n",
       "6   'l'    U+006C       1        2      3   \n",
       "7   'n'    U+006E       1        1      2   \n",
       "8   's'    U+0073       2        6      8   \n",
       "9   't'    U+0074       1        3      4   \n",
       "10  'w'    U+0077       1        1      2   \n",
       "11  'y'    U+0079       1        1      2   \n",
       "\n",
       "                                              Sources  \n",
       "0                                       'A', '·∫ö'‚Üí\"a æ\"  \n",
       "1   'F', 'Ô¨Ä'‚Üí\"ff\", 'Ô¨Å'‚Üí\"fi\", 'Ô¨Ç'‚Üí\"fl\", 'Ô¨É'‚Üí\"ffi\", ...  \n",
       "2                                       'H', '·∫ñ'‚Üí\"hÃ±\"  \n",
       "3                  'I', 'ƒ∞'‚Üí\"iÃá\", 'Ô¨Å'‚Üí\"fi\", 'Ô¨É'‚Üí\"ffi\"  \n",
       "4                                       'J', '«∞'‚Üí\"jÃå\"  \n",
       "5                                            'K', '‚Ñ™'  \n",
       "6                            'L', 'Ô¨Ç'‚Üí\"fl\", 'Ô¨Ñ'‚Üí\"ffl\"  \n",
       "7                                       'N', '≈â'‚Üí\" ºn\"  \n",
       "8    'S', '√ü'‚Üí\"ss\", '≈ø', '·∫û'‚Üí\"ss\", 'Ô¨Ö'‚Üí\"st\", 'Ô¨Ü'‚Üí\"st\"  \n",
       "9                   'T', '·∫ó'‚Üí\"tÃà\", 'Ô¨Ö'‚Üí\"st\", 'Ô¨Ü'‚Üí\"st\"  \n",
       "10                                      'W', '·∫ò'‚Üí\"wÃä\"  \n",
       "11                                      'Y', '·∫ô'‚Üí\"yÃä\"  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguous_rows = []\n",
    "for codepoint in sorted(ambiguous_ascii.keys()):\n",
    "    character = chr(codepoint)\n",
    "    info = ambiguous_ascii[codepoint]\n",
    "\n",
    "    # Find all sources\n",
    "    sources = []\n",
    "    for source_codepoint, target_codepoints in case_folds.items():\n",
    "        if codepoint in target_codepoints:\n",
    "            try:\n",
    "                source_character = chr(source_codepoint)\n",
    "                if len(target_codepoints) == 1:\n",
    "                    sources.append(f\"'{source_character}'\")\n",
    "                else:\n",
    "                    target_string = \"\".join(chr(c) for c in target_codepoints)\n",
    "                    sources.append(f\"'{source_character}'‚Üí\\\"{target_string}\\\"\")\n",
    "            except:\n",
    "                sources.append(f\"U+{source_codepoint:04X}\")\n",
    "\n",
    "    sources_string = \", \".join(sources[:6])\n",
    "    if len(sources) > 6:\n",
    "        sources_string += f\" (+{len(sources)-6} more)\"\n",
    "\n",
    "    ambiguous_rows.append(\n",
    "        {\n",
    "            \"Char\": f\"'{character}'\",\n",
    "            \"Codepoint\": f\"U+{codepoint:04X}\",\n",
    "            \"Direct\": info[\"direct\"],\n",
    "            \"Partial\": info[\"partial\"],\n",
    "            \"Total\": info[\"total\"],\n",
    "            \"Sources\": sources_string,\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame(ambiguous_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, even \"ambiguous\" ASCII characters can be contextually safe based on what follows them in the needle.\n",
    "For example, `'f'` is ambiguous because of ligatures like `'Ô¨Å'` ‚Üí `\"fi\"`.\n",
    "But if the needle contains `\"fog\"`, the `'f'` is safe because no ligature expands to `\"fo...\"`.\n",
    "The following analysis identifies when each ambiguous character becomes safe based on its context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Char</th>\n",
       "      <th>Safe when following</th>\n",
       "      <th>Safe when preceding</th>\n",
       "      <th>Example ligatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'a'</td>\n",
       "      <td>NOT followed by: {' æ'}</td>\n",
       "      <td>any preceding char</td>\n",
       "      <td>'·∫ö'‚Üí\"a æ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'f'</td>\n",
       "      <td>NOT followed by: {'f', 'i', 'l'}</td>\n",
       "      <td>NOT preceded by: {'f'}</td>\n",
       "      <td>'Ô¨Ä'‚Üí\"ff\", 'Ô¨Å'‚Üí\"fi\", 'Ô¨Ç'‚Üí\"fl\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'h'</td>\n",
       "      <td>NOT followed by: {'Ã±'}</td>\n",
       "      <td>any preceding char</td>\n",
       "      <td>'·∫ñ'‚Üí\"hÃ±\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'i'</td>\n",
       "      <td>NOT followed by: {'Ãá'}</td>\n",
       "      <td>NOT preceded by: {'f'}</td>\n",
       "      <td>'ƒ∞'‚Üí\"iÃá\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'j'</td>\n",
       "      <td>NOT followed by: {'Ãå'}</td>\n",
       "      <td>any preceding char</td>\n",
       "      <td>'«∞'‚Üí\"jÃå\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'l'</td>\n",
       "      <td>any following char</td>\n",
       "      <td>NOT preceded by: {'f'}</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'n'</td>\n",
       "      <td>any following char</td>\n",
       "      <td>NOT preceded by: {' º'}</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'s'</td>\n",
       "      <td>NOT followed by: {'s', 't'}</td>\n",
       "      <td>NOT preceded by: {'s'}</td>\n",
       "      <td>'√ü'‚Üí\"ss\", '·∫û'‚Üí\"ss\", 'Ô¨Ö'‚Üí\"st\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'t'</td>\n",
       "      <td>NOT followed by: {'Ãà'}</td>\n",
       "      <td>NOT preceded by: {'s'}</td>\n",
       "      <td>'·∫ó'‚Üí\"tÃà\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'w'</td>\n",
       "      <td>NOT followed by: {'Ãä'}</td>\n",
       "      <td>any preceding char</td>\n",
       "      <td>'·∫ò'‚Üí\"wÃä\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'y'</td>\n",
       "      <td>NOT followed by: {'Ãä'}</td>\n",
       "      <td>any preceding char</td>\n",
       "      <td>'·∫ô'‚Üí\"yÃä\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Char               Safe when following     Safe when preceding  \\\n",
       "0   'a'            NOT followed by: {' æ'}      any preceding char   \n",
       "1   'f'  NOT followed by: {'f', 'i', 'l'}  NOT preceded by: {'f'}   \n",
       "2   'h'            NOT followed by: {'Ã±'}      any preceding char   \n",
       "3   'i'            NOT followed by: {'Ãá'}  NOT preceded by: {'f'}   \n",
       "4   'j'            NOT followed by: {'Ãå'}      any preceding char   \n",
       "5   'l'                any following char  NOT preceded by: {'f'}   \n",
       "6   'n'                any following char  NOT preceded by: {' º'}   \n",
       "7   's'       NOT followed by: {'s', 't'}  NOT preceded by: {'s'}   \n",
       "8   't'            NOT followed by: {'Ãà'}  NOT preceded by: {'s'}   \n",
       "9   'w'            NOT followed by: {'Ãä'}      any preceding char   \n",
       "10  'y'            NOT followed by: {'Ãä'}      any preceding char   \n",
       "\n",
       "               Example ligatures  \n",
       "0                       '·∫ö'‚Üí\"a æ\"  \n",
       "1   'Ô¨Ä'‚Üí\"ff\", 'Ô¨Å'‚Üí\"fi\", 'Ô¨Ç'‚Üí\"fl\"  \n",
       "2                       '·∫ñ'‚Üí\"hÃ±\"  \n",
       "3                       'ƒ∞'‚Üí\"iÃá\"  \n",
       "4                       '«∞'‚Üí\"jÃå\"  \n",
       "5                                 \n",
       "6                                 \n",
       "7   '√ü'‚Üí\"ss\", '·∫û'‚Üí\"ss\", 'Ô¨Ö'‚Üí\"st\"  \n",
       "8                       '·∫ó'‚Üí\"tÃà\"  \n",
       "9                       '·∫ò'‚Üí\"wÃä\"  \n",
       "10                      '·∫ô'‚Üí\"yÃä\"  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_safety = {}\n",
    "\n",
    "for codepoint in ambiguous_ascii.keys():\n",
    "    char = chr(codepoint)\n",
    "    dangerous_following = set()\n",
    "    dangerous_preceding = set()\n",
    "    ligature_examples = []\n",
    "\n",
    "    # Find all multi-codepoint expansions that include this character\n",
    "    for source_codepoint, target_codepoints in case_folds.items():\n",
    "        if len(target_codepoints) > 1:  # Multi-codepoint expansion\n",
    "            expansion = \"\".join(chr(c) for c in target_codepoints)\n",
    "\n",
    "            # Find all positions where our character appears\n",
    "            for pos, c in enumerate(expansion):\n",
    "                if ord(c) == codepoint:\n",
    "                    source_char = chr(source_codepoint)\n",
    "\n",
    "                    # If not the last character, next char is \"dangerous following\"\n",
    "                    if pos < len(expansion) - 1:\n",
    "                        next_char = expansion[pos + 1]\n",
    "                        dangerous_following.add(next_char)\n",
    "                        if len(ligature_examples) < 3:\n",
    "                            ligature_examples.append(f\"'{source_char}'‚Üí\\\"{expansion}\\\"\")\n",
    "\n",
    "                    # If not the first character, prev char is \"dangerous preceding\"\n",
    "                    if pos > 0:\n",
    "                        prev_char = expansion[pos - 1]\n",
    "                        dangerous_preceding.add(prev_char)\n",
    "\n",
    "    if dangerous_following or dangerous_preceding:\n",
    "        contextual_safety[char] = {\n",
    "            \"dangerous_following\": dangerous_following,\n",
    "            \"dangerous_preceding\": dangerous_preceding,\n",
    "            \"examples\": ligature_examples,\n",
    "        }\n",
    "\n",
    "# Build output table\n",
    "context_rows = []\n",
    "for char in sorted(contextual_safety.keys()):\n",
    "    info = contextual_safety[char]\n",
    "    following = info[\"dangerous_following\"]\n",
    "    preceding = info[\"dangerous_preceding\"]\n",
    "\n",
    "    if following:\n",
    "        safe_following = f\"NOT followed by: {{{', '.join(repr(c) for c in sorted(following))}}}\"\n",
    "    else:\n",
    "        safe_following = \"any following char\"\n",
    "\n",
    "    if preceding:\n",
    "        safe_preceding = f\"NOT preceded by: {{{', '.join(repr(c) for c in sorted(preceding))}}}\"\n",
    "    else:\n",
    "        safe_preceding = \"any preceding char\"\n",
    "\n",
    "    context_rows.append(\n",
    "        {\n",
    "            \"Char\": f\"'{char}'\",\n",
    "            \"Safe when following\": safe_following,\n",
    "            \"Safe when preceding\": safe_preceding,\n",
    "            \"Example ligatures\": \", \".join(info[\"examples\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame(context_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this, if the needle contains a continuous sequence of `'b'`, `'c'`, `'d'`, `'e'`, `'g'`, `'m'`, `'o'`, `'p'`, `'q'`, `'r'`, `'u'`, `'v'`, `'x'`, `'z'` in any order or case, we can trivially match them using the simple SIMD snippet from above, as long as it doesn't contain `'a'`, `'f'`, `'h'`, `'i'`, `'j'`, `'k'`, `'l'`, `'n'`, `'s'`, `'t'`, `'w'`, or `'y'`.\n",
    "\n",
    "Moreover, there is a group of single-byte UTF-8 codepoints that don't participate in any folding mappings at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCII codepoints completely uninvolved in folding: 76\n",
      "Control characters: 33 (0x00-0x1F, 0x7F)\n",
      "Digits: 0123456789\n",
      "Punctuation/Symbols:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "uninvolved_ascii = [\n",
    "    codepoint\n",
    "    for codepoint in range(UTF8_1BYTE_MAX + 1)\n",
    "    if codepoint not in ascii_targets and codepoint not in case_folds\n",
    "]\n",
    "print(f\"ASCII codepoints completely uninvolved in folding: {len(uninvolved_ascii)}\")\n",
    "\n",
    "control_characters = [codepoint for codepoint in uninvolved_ascii if codepoint < 32 or codepoint == 127]\n",
    "digits = [chr(codepoint) for codepoint in uninvolved_ascii if chr(codepoint).isdigit()]\n",
    "punctuation = [\n",
    "    chr(codepoint) for codepoint in uninvolved_ascii if 32 <= codepoint < 127 and not chr(codepoint).isalnum()\n",
    "]\n",
    "\n",
    "print(f\"Control characters: {len(control_characters)} (0x00-0x1F, 0x7F)\")\n",
    "print(f\"Digits: {''.join(digits)}\")\n",
    "print(f\"Punctuation/Symbols: {''.join(punctuation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safe Two-byte Folding Anchors\n",
    "\n",
    "The more interesting and challenging part is the 2-byte UTF-8 codepoints that map into either other single 2-byte codepoint or two 1-byte codepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-byte UTF-8 codepoints with case folding: 460\n",
      "\n",
      "Folding patterns for 2-byte UTF-8 sources:\n",
      "  2-byte ‚Üí 1-byte:     1\n",
      "  2-byte ‚Üí 2-byte:     450\n",
      "  2-byte ‚Üí 2x 1-byte:  1\n",
      "  Other patterns:      8\n"
     ]
    }
   ],
   "source": [
    "two_byte_folds = {}\n",
    "for source_codepoint, target_codepoints in case_folds.items():\n",
    "    if UTF8_1BYTE_MAX < source_codepoint <= UTF8_2BYTE_MAX:  # 2-byte UTF-8 range\n",
    "        two_byte_folds[source_codepoint] = target_codepoints\n",
    "\n",
    "print(f\"2-byte UTF-8 codepoints with case folding: {len(two_byte_folds):,}\")\n",
    "print()\n",
    "\n",
    "# Categorize by target type\n",
    "folds_to_1byte = {}  # 2-byte ‚Üí single 1-byte (e.g., some Latin letters)\n",
    "folds_to_2byte = {}  # 2-byte ‚Üí single 2-byte (most common)\n",
    "folds_to_2x1byte = {}  # 2-byte ‚Üí two 1-byte codepoints\n",
    "folds_to_other = {}  # Other patterns\n",
    "\n",
    "for source_codepoint, target_codepoints in two_byte_folds.items():\n",
    "    target_sizes = [\n",
    "        (\n",
    "            1\n",
    "            if codepoint <= UTF8_1BYTE_MAX\n",
    "            else 2 if codepoint <= UTF8_2BYTE_MAX else 3 if codepoint <= UTF8_3BYTE_MAX else 4\n",
    "        )\n",
    "        for codepoint in target_codepoints\n",
    "    ]\n",
    "\n",
    "    if len(target_codepoints) == 1:\n",
    "        if target_sizes[0] == 1:\n",
    "            folds_to_1byte[source_codepoint] = target_codepoints\n",
    "        elif target_sizes[0] == 2:\n",
    "            folds_to_2byte[source_codepoint] = target_codepoints\n",
    "        else:\n",
    "            folds_to_other[source_codepoint] = target_codepoints\n",
    "    elif len(target_codepoints) == 2 and all(size == 1 for size in target_sizes):\n",
    "        folds_to_2x1byte[source_codepoint] = target_codepoints\n",
    "    else:\n",
    "        folds_to_other[source_codepoint] = target_codepoints\n",
    "\n",
    "print(f\"Folding patterns for 2-byte UTF-8 sources:\")\n",
    "print(f\"  2-byte ‚Üí 1-byte:     {len(folds_to_1byte):,}\")\n",
    "print(f\"  2-byte ‚Üí 2-byte:     {len(folds_to_2byte):,}\")\n",
    "print(f\"  2-byte ‚Üí 2x 1-byte:  {len(folds_to_2x1byte):,}\")\n",
    "print(f\"  Other patterns:      {len(folds_to_other):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 460 case folding rules for 2-byte UTF-8 sources, the vast majority (450) map to another 2-byte codepoint.\n",
    "The remaining 10 are special cases worth understanding:\n",
    "\n",
    "__2-byte ‚Üí 1-byte (1 case):__\n",
    "\n",
    "- `'≈ø'` (U+017F, LATIN SMALL LETTER LONG S) ‚Üí `'s'` - historical long S folds to regular ASCII s\n",
    "\n",
    "__2-byte ‚Üí 2x 1-byte (1 case):__\n",
    "\n",
    "- `'√ü'` (U+00DF, LATIN SMALL LETTER SHARP S) ‚Üí `\"ss\"` - German eszett expands to two ASCII characters\n",
    "\n",
    "__Other patterns (8 cases):__\n",
    "\n",
    "These are the tricky edge cases that don't fit clean patterns:\n",
    "\n",
    "- `'ƒ∞'` (U+0130) ‚Üí `'i'` + combining dot above (1-byte + 2-byte) - Turkish capital I with dot\n",
    "- `'≈â'` (U+0149) ‚Üí modifier apostrophe + `'n'` (2-byte + 1-byte) - deprecated character\n",
    "- `'«∞'` (U+01F0) ‚Üí `'j'` + combining caron (1-byte + 2-byte) - J with caron decomposes\n",
    "- `'»∫'` (U+023A) ‚Üí `'‚±•'` (U+2C65) - 2-byte source maps to 3-byte target!\n",
    "- `'»æ'` (U+023E) ‚Üí `'‚±¶'` (U+2C66) - another 2-byte ‚Üí 3-byte case\n",
    "- `'Œê'` (U+0390) ‚Üí Œπ + combining diaeresis + combining acute (3x 2-byte) - Greek with diacritics\n",
    "- `'Œ∞'` (U+03B0) ‚Üí œÖ + combining diaeresis + combining acute (3x 2-byte) - Greek with diacritics\n",
    "- `'÷á'` (U+0587) ‚Üí ’• + ÷Ç (2x 2-byte) - Armenian ligature\n",
    "\n",
    "The `'»∫'` and `'»æ'` cases are particularly noteworthy: they are 2-byte UTF-8 sources that fold to 3-byte targets, meaning the folded form is *longer* than the original!\n",
    "\n",
    "Assuming the much larger search space, where possible, we want to group them into continuous to/from ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows continuous ranges of 2-byte UTF-8 codepoints that fold to other 2-byte codepoints with a constant offset (e.g., uppercase ‚Üí lowercase within the same script block):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 308 continuous ranges of 2-byte ‚Üí 2-byte foldings\n",
      "Ranges of length > 1: 12\n",
      "Single-codepoint 'ranges': 296\n",
      "\n",
      "Multi-codepoint ranges (useful for SIMD optimization):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Start</th>\n",
       "      <th>Source End</th>\n",
       "      <th>Target Start</th>\n",
       "      <th>Target End</th>\n",
       "      <th>Length</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U+00C0 (√Ä)</td>\n",
       "      <td>U+00D6 (√ñ)</td>\n",
       "      <td>U+00E0 (√†)</td>\n",
       "      <td>U+00F6 (√∂)</td>\n",
       "      <td>23</td>\n",
       "      <td>+32</td>\n",
       "      <td>LATIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U+00D8 (√ò)</td>\n",
       "      <td>U+00DE (√û)</td>\n",
       "      <td>U+00F8 (√∏)</td>\n",
       "      <td>U+00FE (√æ)</td>\n",
       "      <td>7</td>\n",
       "      <td>+32</td>\n",
       "      <td>LATIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U+0189 (∆â)</td>\n",
       "      <td>U+018A (∆ä)</td>\n",
       "      <td>U+0256 (…ñ)</td>\n",
       "      <td>U+0257 (…ó)</td>\n",
       "      <td>2</td>\n",
       "      <td>+205</td>\n",
       "      <td>LATIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U+01B1 (∆±)</td>\n",
       "      <td>U+01B2 (∆≤)</td>\n",
       "      <td>U+028A ( ä)</td>\n",
       "      <td>U+028B ( ã)</td>\n",
       "      <td>2</td>\n",
       "      <td>+217</td>\n",
       "      <td>LATIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U+0388 (Œà)</td>\n",
       "      <td>U+038A (Œä)</td>\n",
       "      <td>U+03AD (Œ≠)</td>\n",
       "      <td>U+03AF (ŒØ)</td>\n",
       "      <td>3</td>\n",
       "      <td>+37</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U+038E (Œé)</td>\n",
       "      <td>U+038F (Œè)</td>\n",
       "      <td>U+03CD (œç)</td>\n",
       "      <td>U+03CE (œé)</td>\n",
       "      <td>2</td>\n",
       "      <td>+63</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U+0391 (Œë)</td>\n",
       "      <td>U+03A1 (Œ°)</td>\n",
       "      <td>U+03B1 (Œ±)</td>\n",
       "      <td>U+03C1 (œÅ)</td>\n",
       "      <td>17</td>\n",
       "      <td>+32</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U+03A3 (Œ£)</td>\n",
       "      <td>U+03AB (Œ´)</td>\n",
       "      <td>U+03C3 (œÉ)</td>\n",
       "      <td>U+03CB (œã)</td>\n",
       "      <td>9</td>\n",
       "      <td>+32</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U+03FD (œΩ)</td>\n",
       "      <td>U+03FF (œø)</td>\n",
       "      <td>U+037B (Õª)</td>\n",
       "      <td>U+037D (ÕΩ)</td>\n",
       "      <td>3</td>\n",
       "      <td>-130</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U+0400 (–Ä)</td>\n",
       "      <td>U+040F (–è)</td>\n",
       "      <td>U+0450 (—ê)</td>\n",
       "      <td>U+045F (—ü)</td>\n",
       "      <td>16</td>\n",
       "      <td>+80</td>\n",
       "      <td>CYRILLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U+0410 (–ê)</td>\n",
       "      <td>U+042F (–Ø)</td>\n",
       "      <td>U+0430 (–∞)</td>\n",
       "      <td>U+044F (—è)</td>\n",
       "      <td>32</td>\n",
       "      <td>+32</td>\n",
       "      <td>CYRILLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>U+0531 (‘±)</td>\n",
       "      <td>U+0556 (’ñ)</td>\n",
       "      <td>U+0561 (’°)</td>\n",
       "      <td>U+0586 (÷Ü)</td>\n",
       "      <td>38</td>\n",
       "      <td>+48</td>\n",
       "      <td>ARMENIAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source Start  Source End Target Start  Target End  Length Offset    Script\n",
       "0    U+00C0 (√Ä)  U+00D6 (√ñ)   U+00E0 (√†)  U+00F6 (√∂)      23    +32     LATIN\n",
       "1    U+00D8 (√ò)  U+00DE (√û)   U+00F8 (√∏)  U+00FE (√æ)       7    +32     LATIN\n",
       "2    U+0189 (∆â)  U+018A (∆ä)   U+0256 (…ñ)  U+0257 (…ó)       2   +205     LATIN\n",
       "3    U+01B1 (∆±)  U+01B2 (∆≤)   U+028A ( ä)  U+028B ( ã)       2   +217     LATIN\n",
       "4    U+0388 (Œà)  U+038A (Œä)   U+03AD (Œ≠)  U+03AF (ŒØ)       3    +37     GREEK\n",
       "5    U+038E (Œé)  U+038F (Œè)   U+03CD (œç)  U+03CE (œé)       2    +63     GREEK\n",
       "6    U+0391 (Œë)  U+03A1 (Œ°)   U+03B1 (Œ±)  U+03C1 (œÅ)      17    +32     GREEK\n",
       "7    U+03A3 (Œ£)  U+03AB (Œ´)   U+03C3 (œÉ)  U+03CB (œã)       9    +32     GREEK\n",
       "8    U+03FD (œΩ)  U+03FF (œø)   U+037B (Õª)  U+037D (ÕΩ)       3   -130     GREEK\n",
       "9    U+0400 (–Ä)  U+040F (–è)   U+0450 (—ê)  U+045F (—ü)      16    +80  CYRILLIC\n",
       "10   U+0410 (–ê)  U+042F (–Ø)   U+0430 (–∞)  U+044F (—è)      32    +32  CYRILLIC\n",
       "11   U+0531 (‘±)  U+0556 (’ñ)   U+0561 (’°)  U+0586 (÷Ü)      38    +48  ARMENIAN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find continuous ranges of 2-byte ‚Üí 2-byte foldings with constant offset\n",
    "# Sort by source codepoint to find consecutive sequences\n",
    "sorted_2byte = sorted(folds_to_2byte.items())\n",
    "\n",
    "ranges = []\n",
    "if sorted_2byte:\n",
    "    range_start = sorted_2byte[0][0]\n",
    "    range_offset = sorted_2byte[0][1][0] - sorted_2byte[0][0]\n",
    "    prev_source = sorted_2byte[0][0]\n",
    "\n",
    "    for source_codepoint, target_codepoints in sorted_2byte[1:]:\n",
    "        target_codepoint = target_codepoints[0]\n",
    "        current_offset = target_codepoint - source_codepoint\n",
    "\n",
    "        # Check if this continues the current range (consecutive source AND same offset)\n",
    "        if source_codepoint == prev_source + 1 and current_offset == range_offset:\n",
    "            prev_source = source_codepoint\n",
    "        else:\n",
    "            # End the current range and start a new one\n",
    "            ranges.append((range_start, prev_source, range_offset))\n",
    "            range_start = source_codepoint\n",
    "            range_offset = current_offset\n",
    "            prev_source = source_codepoint\n",
    "\n",
    "    # Don't forget the last range\n",
    "    ranges.append((range_start, prev_source, range_offset))\n",
    "\n",
    "# Build DataFrame with range information\n",
    "range_rows = []\n",
    "for start, end, offset in ranges:\n",
    "    length = end - start + 1\n",
    "    try:\n",
    "        start_char = chr(start)\n",
    "        end_char = chr(end)\n",
    "        target_start_char = chr(start + offset)\n",
    "        target_end_char = chr(end + offset)\n",
    "        script = unicodedata.name(start_char, \"\").split()[0] if length > 1 else \"\"\n",
    "    except (ValueError, OverflowError):\n",
    "        start_char = end_char = target_start_char = target_end_char = \"?\"\n",
    "        script = \"\"\n",
    "\n",
    "    range_rows.append(\n",
    "        {\n",
    "            \"Source Start\": f\"U+{start:04X} ({start_char})\",\n",
    "            \"Source End\": f\"U+{end:04X} ({end_char})\",\n",
    "            \"Target Start\": f\"U+{start + offset:04X} ({target_start_char})\",\n",
    "            \"Target End\": f\"U+{end + offset:04X} ({target_end_char})\",\n",
    "            \"Length\": length,\n",
    "            \"Offset\": f\"+{offset}\" if offset > 0 else str(offset),\n",
    "            \"Script\": script,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"Found {len(ranges)} continuous ranges of 2-byte ‚Üí 2-byte foldings\")\n",
    "print(f\"Ranges of length > 1: {sum(1 for r in ranges if r[1] - r[0] > 0)}\")\n",
    "print(f\"Single-codepoint 'ranges': {sum(1 for r in ranges if r[1] == r[0])}\")\n",
    "print()\n",
    "\n",
    "# Show only ranges with length > 1 (the interesting ones for SIMD)\n",
    "multi_ranges = [r for r in range_rows if r[\"Length\"] > 1]\n",
    "print(f\"Multi-codepoint ranges (useful for SIMD optimization):\")\n",
    "pd.DataFrame(multi_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-byte UTF-8 Case Folding\n",
    "\n",
    "3-byte UTF-8 covers codepoints U+0800 to U+FFFF (2048 to 65535).\n",
    "This includes many scripts: Extended Greek, Cherokee, Georgian, and various symbol blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-byte UTF-8 codepoints with case folding: 792\n",
      "\n",
      "Folding patterns for 3-byte UTF-8 sources:\n",
      "  3-byte ‚Üí 3-byte:  663\n",
      "  3-byte ‚Üí 2-byte:  31\n",
      "  3-byte ‚Üí 1-byte:  1\n",
      "  Other patterns:   97\n"
     ]
    }
   ],
   "source": [
    "# 3-byte UTF-8 codepoints: U+0800 to U+FFFF (2048 to 65535)\n",
    "three_byte_folds = {}\n",
    "for source_codepoint, target_codepoints in case_folds.items():\n",
    "    if UTF8_2BYTE_MAX < source_codepoint <= UTF8_3BYTE_MAX:\n",
    "        three_byte_folds[source_codepoint] = target_codepoints\n",
    "\n",
    "print(f\"3-byte UTF-8 codepoints with case folding: {len(three_byte_folds):,}\")\n",
    "print()\n",
    "\n",
    "# Categorize by target pattern\n",
    "three_to_3byte = {}  # 3-byte ‚Üí single 3-byte\n",
    "three_to_2byte = {}  # 3-byte ‚Üí single 2-byte (shrinks!)\n",
    "three_to_1byte = {}  # 3-byte ‚Üí 1-byte sequence\n",
    "three_to_other = {}  # Multi-codepoint or mixed\n",
    "\n",
    "for source_codepoint, target_codepoints in three_byte_folds.items():\n",
    "    target_sizes = [\n",
    "        1 if cp <= UTF8_1BYTE_MAX else 2 if cp <= UTF8_2BYTE_MAX else 3 if cp <= UTF8_3BYTE_MAX else 4\n",
    "        for cp in target_codepoints\n",
    "    ]\n",
    "\n",
    "    if len(target_codepoints) == 1:\n",
    "        if target_sizes[0] == 3:\n",
    "            three_to_3byte[source_codepoint] = target_codepoints\n",
    "        elif target_sizes[0] == 2:\n",
    "            three_to_2byte[source_codepoint] = target_codepoints\n",
    "        elif target_sizes[0] == 1:\n",
    "            three_to_1byte[source_codepoint] = target_codepoints\n",
    "        else:\n",
    "            three_to_other[source_codepoint] = target_codepoints\n",
    "    else:\n",
    "        three_to_other[source_codepoint] = target_codepoints\n",
    "\n",
    "print(f\"Folding patterns for 3-byte UTF-8 sources:\")\n",
    "print(f\"  3-byte ‚Üí 3-byte:  {len(three_to_3byte):,}\")\n",
    "print(f\"  3-byte ‚Üí 2-byte:  {len(three_to_2byte):,}\")\n",
    "print(f\"  3-byte ‚Üí 1-byte:  {len(three_to_1byte):,}\")\n",
    "print(f\"  Other patterns:   {len(three_to_other):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows continuous ranges of 3-byte UTF-8 codepoints that fold to other 3-byte codepoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 337 continuous ranges of 3-byte ‚Üí 3-byte foldings\n",
      "Ranges of length > 1: 24\n",
      "Single-codepoint 'ranges': 313\n",
      "\n",
      "Multi-codepoint ranges (useful for SIMD optimization):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Start</th>\n",
       "      <th>Source End</th>\n",
       "      <th>Target Start</th>\n",
       "      <th>Target End</th>\n",
       "      <th>Length</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U+10A0 (·Ç†)</td>\n",
       "      <td>U+10C5 (·ÉÖ)</td>\n",
       "      <td>U+2D00 (‚¥Ä)</td>\n",
       "      <td>U+2D25 (‚¥•)</td>\n",
       "      <td>38</td>\n",
       "      <td>+7264</td>\n",
       "      <td>GEORGIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U+13F8 (·è∏)</td>\n",
       "      <td>U+13FD (·èΩ)</td>\n",
       "      <td>U+13F0 (·è∞)</td>\n",
       "      <td>U+13F5 (·èµ)</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>CHEROKEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U+1C90 (·≤ê)</td>\n",
       "      <td>U+1CBA (·≤∫)</td>\n",
       "      <td>U+10D0 (·Éê)</td>\n",
       "      <td>U+10FA (·É∫)</td>\n",
       "      <td>43</td>\n",
       "      <td>-3008</td>\n",
       "      <td>GEORGIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U+1CBD (·≤Ω)</td>\n",
       "      <td>U+1CBF (·≤ø)</td>\n",
       "      <td>U+10FD (·ÉΩ)</td>\n",
       "      <td>U+10FF (·Éø)</td>\n",
       "      <td>3</td>\n",
       "      <td>-3008</td>\n",
       "      <td>GEORGIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U+1F08 (·ºà)</td>\n",
       "      <td>U+1F0F (·ºè)</td>\n",
       "      <td>U+1F00 (·ºÄ)</td>\n",
       "      <td>U+1F07 (·ºá)</td>\n",
       "      <td>8</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U+1F18 (·ºò)</td>\n",
       "      <td>U+1F1D (·ºù)</td>\n",
       "      <td>U+1F10 (·ºê)</td>\n",
       "      <td>U+1F15 (·ºï)</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U+1F28 (·º®)</td>\n",
       "      <td>U+1F2F (·ºØ)</td>\n",
       "      <td>U+1F20 (·º†)</td>\n",
       "      <td>U+1F27 (·ºß)</td>\n",
       "      <td>8</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U+1F38 (·º∏)</td>\n",
       "      <td>U+1F3F (·ºø)</td>\n",
       "      <td>U+1F30 (·º∞)</td>\n",
       "      <td>U+1F37 (·º∑)</td>\n",
       "      <td>8</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U+1F48 (·Ωà)</td>\n",
       "      <td>U+1F4D (·Ωç)</td>\n",
       "      <td>U+1F40 (·ΩÄ)</td>\n",
       "      <td>U+1F45 (·ΩÖ)</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U+1F68 (·Ω®)</td>\n",
       "      <td>U+1F6F (·ΩØ)</td>\n",
       "      <td>U+1F60 (·Ω†)</td>\n",
       "      <td>U+1F67 (·Ωß)</td>\n",
       "      <td>8</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U+1FB8 (·æ∏)</td>\n",
       "      <td>U+1FB9 (·æπ)</td>\n",
       "      <td>U+1FB0 (·æ∞)</td>\n",
       "      <td>U+1FB1 (·æ±)</td>\n",
       "      <td>2</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>U+1FBA (·æ∫)</td>\n",
       "      <td>U+1FBB (·æª)</td>\n",
       "      <td>U+1F70 (·Ω∞)</td>\n",
       "      <td>U+1F71 (·Ω±)</td>\n",
       "      <td>2</td>\n",
       "      <td>-74</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>U+1FC8 (·øà)</td>\n",
       "      <td>U+1FCB (·øã)</td>\n",
       "      <td>U+1F72 (·Ω≤)</td>\n",
       "      <td>U+1F75 (·Ωµ)</td>\n",
       "      <td>4</td>\n",
       "      <td>-86</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>U+1FD8 (·øò)</td>\n",
       "      <td>U+1FD9 (·øô)</td>\n",
       "      <td>U+1FD0 (·øê)</td>\n",
       "      <td>U+1FD1 (·øë)</td>\n",
       "      <td>2</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>U+1FDA (·øö)</td>\n",
       "      <td>U+1FDB (·øõ)</td>\n",
       "      <td>U+1F76 (·Ω∂)</td>\n",
       "      <td>U+1F77 (·Ω∑)</td>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>U+1FE8 (·ø®)</td>\n",
       "      <td>U+1FE9 (·ø©)</td>\n",
       "      <td>U+1FE0 (·ø†)</td>\n",
       "      <td>U+1FE1 (·ø°)</td>\n",
       "      <td>2</td>\n",
       "      <td>-8</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>U+1FEA (·ø™)</td>\n",
       "      <td>U+1FEB (·ø´)</td>\n",
       "      <td>U+1F7A (·Ω∫)</td>\n",
       "      <td>U+1F7B (·Ωª)</td>\n",
       "      <td>2</td>\n",
       "      <td>-112</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>U+1FF8 (·ø∏)</td>\n",
       "      <td>U+1FF9 (·øπ)</td>\n",
       "      <td>U+1F78 (·Ω∏)</td>\n",
       "      <td>U+1F79 (·Ωπ)</td>\n",
       "      <td>2</td>\n",
       "      <td>-128</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>U+1FFA (·ø∫)</td>\n",
       "      <td>U+1FFB (·øª)</td>\n",
       "      <td>U+1F7C (·Ωº)</td>\n",
       "      <td>U+1F7D (·ΩΩ)</td>\n",
       "      <td>2</td>\n",
       "      <td>-126</td>\n",
       "      <td>GREEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>U+2160 (‚Ö†)</td>\n",
       "      <td>U+216F (‚ÖØ)</td>\n",
       "      <td>U+2170 (‚Ö∞)</td>\n",
       "      <td>U+217F (‚Öø)</td>\n",
       "      <td>16</td>\n",
       "      <td>+16</td>\n",
       "      <td>ROMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>U+24B6 (‚í∂)</td>\n",
       "      <td>U+24CF (‚ìè)</td>\n",
       "      <td>U+24D0 (‚ìê)</td>\n",
       "      <td>U+24E9 (‚ì©)</td>\n",
       "      <td>26</td>\n",
       "      <td>+26</td>\n",
       "      <td>CIRCLED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>U+2C00 (‚∞Ä)</td>\n",
       "      <td>U+2C2F (‚∞Ø)</td>\n",
       "      <td>U+2C30 (‚∞∞)</td>\n",
       "      <td>U+2C5F (‚±ü)</td>\n",
       "      <td>48</td>\n",
       "      <td>+48</td>\n",
       "      <td>GLAGOLITIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>U+AB70 (Í≠∞)</td>\n",
       "      <td>U+ABBF (ÍÆø)</td>\n",
       "      <td>U+13A0 (·é†)</td>\n",
       "      <td>U+13EF (·èØ)</td>\n",
       "      <td>80</td>\n",
       "      <td>-38864</td>\n",
       "      <td>CHEROKEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>U+FF21 (Ôº°)</td>\n",
       "      <td>U+FF3A (Ôº∫)</td>\n",
       "      <td>U+FF41 (ÔΩÅ)</td>\n",
       "      <td>U+FF5A (ÔΩö)</td>\n",
       "      <td>26</td>\n",
       "      <td>+32</td>\n",
       "      <td>FULLWIDTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source Start  Source End Target Start  Target End  Length  Offset  \\\n",
       "0    U+10A0 (·Ç†)  U+10C5 (·ÉÖ)   U+2D00 (‚¥Ä)  U+2D25 (‚¥•)      38   +7264   \n",
       "1    U+13F8 (·è∏)  U+13FD (·èΩ)   U+13F0 (·è∞)  U+13F5 (·èµ)       6      -8   \n",
       "2    U+1C90 (·≤ê)  U+1CBA (·≤∫)   U+10D0 (·Éê)  U+10FA (·É∫)      43   -3008   \n",
       "3    U+1CBD (·≤Ω)  U+1CBF (·≤ø)   U+10FD (·ÉΩ)  U+10FF (·Éø)       3   -3008   \n",
       "4    U+1F08 (·ºà)  U+1F0F (·ºè)   U+1F00 (·ºÄ)  U+1F07 (·ºá)       8      -8   \n",
       "5    U+1F18 (·ºò)  U+1F1D (·ºù)   U+1F10 (·ºê)  U+1F15 (·ºï)       6      -8   \n",
       "6    U+1F28 (·º®)  U+1F2F (·ºØ)   U+1F20 (·º†)  U+1F27 (·ºß)       8      -8   \n",
       "7    U+1F38 (·º∏)  U+1F3F (·ºø)   U+1F30 (·º∞)  U+1F37 (·º∑)       8      -8   \n",
       "8    U+1F48 (·Ωà)  U+1F4D (·Ωç)   U+1F40 (·ΩÄ)  U+1F45 (·ΩÖ)       6      -8   \n",
       "9    U+1F68 (·Ω®)  U+1F6F (·ΩØ)   U+1F60 (·Ω†)  U+1F67 (·Ωß)       8      -8   \n",
       "10   U+1FB8 (·æ∏)  U+1FB9 (·æπ)   U+1FB0 (·æ∞)  U+1FB1 (·æ±)       2      -8   \n",
       "11   U+1FBA (·æ∫)  U+1FBB (·æª)   U+1F70 (·Ω∞)  U+1F71 (·Ω±)       2     -74   \n",
       "12   U+1FC8 (·øà)  U+1FCB (·øã)   U+1F72 (·Ω≤)  U+1F75 (·Ωµ)       4     -86   \n",
       "13   U+1FD8 (·øò)  U+1FD9 (·øô)   U+1FD0 (·øê)  U+1FD1 (·øë)       2      -8   \n",
       "14   U+1FDA (·øö)  U+1FDB (·øõ)   U+1F76 (·Ω∂)  U+1F77 (·Ω∑)       2    -100   \n",
       "15   U+1FE8 (·ø®)  U+1FE9 (·ø©)   U+1FE0 (·ø†)  U+1FE1 (·ø°)       2      -8   \n",
       "16   U+1FEA (·ø™)  U+1FEB (·ø´)   U+1F7A (·Ω∫)  U+1F7B (·Ωª)       2    -112   \n",
       "17   U+1FF8 (·ø∏)  U+1FF9 (·øπ)   U+1F78 (·Ω∏)  U+1F79 (·Ωπ)       2    -128   \n",
       "18   U+1FFA (·ø∫)  U+1FFB (·øª)   U+1F7C (·Ωº)  U+1F7D (·ΩΩ)       2    -126   \n",
       "19   U+2160 (‚Ö†)  U+216F (‚ÖØ)   U+2170 (‚Ö∞)  U+217F (‚Öø)      16     +16   \n",
       "20   U+24B6 (‚í∂)  U+24CF (‚ìè)   U+24D0 (‚ìê)  U+24E9 (‚ì©)      26     +26   \n",
       "21   U+2C00 (‚∞Ä)  U+2C2F (‚∞Ø)   U+2C30 (‚∞∞)  U+2C5F (‚±ü)      48     +48   \n",
       "22   U+AB70 (Í≠∞)  U+ABBF (ÍÆø)   U+13A0 (·é†)  U+13EF (·èØ)      80  -38864   \n",
       "23   U+FF21 (Ôº°)  U+FF3A (Ôº∫)   U+FF41 (ÔΩÅ)  U+FF5A (ÔΩö)      26     +32   \n",
       "\n",
       "        Script  \n",
       "0     GEORGIAN  \n",
       "1     CHEROKEE  \n",
       "2     GEORGIAN  \n",
       "3     GEORGIAN  \n",
       "4        GREEK  \n",
       "5        GREEK  \n",
       "6        GREEK  \n",
       "7        GREEK  \n",
       "8        GREEK  \n",
       "9        GREEK  \n",
       "10       GREEK  \n",
       "11       GREEK  \n",
       "12       GREEK  \n",
       "13       GREEK  \n",
       "14       GREEK  \n",
       "15       GREEK  \n",
       "16       GREEK  \n",
       "17       GREEK  \n",
       "18       GREEK  \n",
       "19       ROMAN  \n",
       "20     CIRCLED  \n",
       "21  GLAGOLITIC  \n",
       "22    CHEROKEE  \n",
       "23   FULLWIDTH  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find continuous ranges of 3-byte ‚Üí 3-byte foldings\n",
    "sorted_3byte = sorted(three_to_3byte.items())\n",
    "\n",
    "ranges_3byte = []\n",
    "if sorted_3byte:\n",
    "    range_start = sorted_3byte[0][0]\n",
    "    range_offset = sorted_3byte[0][1][0] - sorted_3byte[0][0]\n",
    "    prev_source = sorted_3byte[0][0]\n",
    "\n",
    "    for source_codepoint, target_codepoints in sorted_3byte[1:]:\n",
    "        target_codepoint = target_codepoints[0]\n",
    "        current_offset = target_codepoint - source_codepoint\n",
    "\n",
    "        if source_codepoint == prev_source + 1 and current_offset == range_offset:\n",
    "            prev_source = source_codepoint\n",
    "        else:\n",
    "            ranges_3byte.append((range_start, prev_source, range_offset))\n",
    "            range_start = source_codepoint\n",
    "            range_offset = current_offset\n",
    "            prev_source = source_codepoint\n",
    "\n",
    "    ranges_3byte.append((range_start, prev_source, range_offset))\n",
    "\n",
    "# Build DataFrame\n",
    "range_rows_3byte = []\n",
    "for start, end, offset in ranges_3byte:\n",
    "    length = end - start + 1\n",
    "    try:\n",
    "        start_char = chr(start)\n",
    "        end_char = chr(end)\n",
    "        target_start_char = chr(start + offset)\n",
    "        target_end_char = chr(end + offset)\n",
    "        script = unicodedata.name(start_char, \"\").split()[0] if length > 1 else \"\"\n",
    "    except (ValueError, OverflowError):\n",
    "        start_char = end_char = target_start_char = target_end_char = \"?\"\n",
    "        script = \"\"\n",
    "\n",
    "    range_rows_3byte.append(\n",
    "        {\n",
    "            \"Source Start\": f\"U+{start:04X} ({start_char})\",\n",
    "            \"Source End\": f\"U+{end:04X} ({end_char})\",\n",
    "            \"Target Start\": f\"U+{start + offset:04X} ({target_start_char})\",\n",
    "            \"Target End\": f\"U+{end + offset:04X} ({target_end_char})\",\n",
    "            \"Length\": length,\n",
    "            \"Offset\": f\"+{offset}\" if offset > 0 else str(offset),\n",
    "            \"Script\": script,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"Found {len(ranges_3byte)} continuous ranges of 3-byte ‚Üí 3-byte foldings\")\n",
    "print(f\"Ranges of length > 1: {sum(1 for r in ranges_3byte if r[1] - r[0] > 0)}\")\n",
    "print(f\"Single-codepoint 'ranges': {sum(1 for r in ranges_3byte if r[1] == r[0])}\")\n",
    "print()\n",
    "\n",
    "multi_ranges_3byte = [r for r in range_rows_3byte if r[\"Length\"] > 1]\n",
    "print(f\"Multi-codepoint ranges (useful for SIMD optimization):\")\n",
    "pd.DataFrame(multi_ranges_3byte)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StringZilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
