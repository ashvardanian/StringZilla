{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode Normalization and Search Anchor Analysis\n",
    "\n",
    "This notebook explores Unicode case folding and normalization properties to identify optimal\n",
    "\"anchor points\" for case-insensitive and normalization-insensitive string search algorithms.\n",
    "\n",
    "**Key insight:** For fast UTF-8 search, we want to find characters that:\n",
    "1. Are invariant under case folding (don't change when folded)\n",
    "2. Are invariant under normalization (NFC, NFD, NFKC, NFKD)\n",
    "3. Are not targets of multiple other characters' transformations\n",
    "4. Have high byte-level entropy (good for SIMD pattern matching)\n",
    "\n",
    "These \"anchor points\" can be used to quickly scan for potential matches before\n",
    "performing expensive case-insensitive or normalized comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Unicode version: 17.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "\n",
    "# Import shared Unicode data loading functions\n",
    "sys.path.insert(0, '.')\n",
    "from test_stringzilla import (\n",
    "    UNICODE_VERSION,\n",
    "    get_case_folding_rules,\n",
    "    get_case_folding_rules_as_codepoints,\n",
    "    get_normalization_props,\n",
    "    get_unicode_xml_data,\n",
    ")\n",
    "\n",
    "print(f\"Using Unicode version: {UNICODE_VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Case Folding Analysis\n",
    "\n",
    "Case folding maps characters to a \"folded\" form for case-insensitive comparisons.\n",
    "This is more comprehensive than simple lowercasing - it handles special cases like German ß → ss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Unicode 17.0.0 CaseFolding.txt from https://www.unicode.org/Public/17.0.0/ucd/CaseFolding.txt...\n",
      "Cached to /tmp/CaseFolding-17.0.0.txt\n",
      "Total case folding rules: 1,585\n"
     ]
    }
   ],
   "source": [
    "# Load case folding rules\n",
    "case_folds = get_case_folding_rules_as_codepoints(UNICODE_VERSION)\n",
    "print(f\"Total case folding rules: {len(case_folds):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique target codepoints: 1,462\n",
      "Total target occurrences: 1,705\n"
     ]
    }
   ],
   "source": [
    "# Count how often each codepoint appears as a case folding TARGET\n",
    "target_frequency = Counter()\n",
    "\n",
    "for source_cp, target_cps in case_folds.items():\n",
    "    for target_cp in target_cps:\n",
    "        target_frequency[target_cp] += 1\n",
    "\n",
    "print(f\"Total folding rules: {sum(target_frequency.values()):,}\")\n",
    "print(f\"Unique target codepoints: {len(target_frequency):,}\")\n",
    "\n",
    "# Characters that map to themselves are not in the table, so targets with\n",
    "# frequency > 0 are characters that OTHER characters fold into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common case folding targets:\n",
      "======================================================================\n",
      "Codepoint    Char   Freq   Name\n",
      "----------------------------------------------------------------------\n",
      "U+03B9       'ι'    71     GREEK SMALL LETTER IOTA\n",
      "U+0342       '͂'    11     COMBINING GREEK PERISPOMENI\n",
      "U+03C5       'υ'    10     GREEK SMALL LETTER UPSILON\n",
      "U+0066       'f'    9      LATIN SMALL LETTER F\n",
      "U+0308       '̈'    9      COMBINING DIAERESIS\n",
      "U+0073       's'    8      LATIN SMALL LETTER S\n",
      "U+03C9       'ω'    6      GREEK SMALL LETTER OMEGA\n",
      "U+0301       '́'    5      COMBINING ACUTE ACCENT\n",
      "U+03B1       'α'    5      GREEK SMALL LETTER ALPHA\n",
      "U+03B7       'η'    5      GREEK SMALL LETTER ETA\n",
      "U+0574       'մ'    5      ARMENIAN SMALL LETTER MEN\n",
      "U+0313       '̓'    5      COMBINING COMMA ABOVE\n",
      "U+0069       'i'    4      LATIN SMALL LETTER I\n",
      "U+0074       't'    4      LATIN SMALL LETTER T\n",
      "U+006C       'l'    3      LATIN SMALL LETTER L\n",
      "U+03B8       'θ'    3      GREEK SMALL LETTER THETA\n",
      "U+03C1       'ρ'    3      GREEK SMALL LETTER RHO\n",
      "U+0442       'т'    3      CYRILLIC SMALL LETTER TE\n",
      "U+0565       'ե'    3      ARMENIAN SMALL LETTER ECH\n",
      "U+0576       'ն'    3      ARMENIAN SMALL LETTER NOW\n",
      "U+1F00       'ἀ'    3      GREEK SMALL LETTER ALPHA WITH PSILI\n",
      "U+1F01       'ἁ'    3      GREEK SMALL LETTER ALPHA WITH DASIA\n",
      "U+1F02       'ἂ'    3      GREEK SMALL LETTER ALPHA WITH PSILI AND VARIA\n",
      "U+1F03       'ἃ'    3      GREEK SMALL LETTER ALPHA WITH DASIA AND VARIA\n",
      "U+1F04       'ἄ'    3      GREEK SMALL LETTER ALPHA WITH PSILI AND OXIA\n",
      "U+1F05       'ἅ'    3      GREEK SMALL LETTER ALPHA WITH DASIA AND OXIA\n",
      "U+1F06       'ἆ'    3      GREEK SMALL LETTER ALPHA WITH PSILI AND PERISPOMENI\n",
      "U+1F07       'ἇ'    3      GREEK SMALL LETTER ALPHA WITH DASIA AND PERISPOMENI\n",
      "U+1F20       'ἠ'    3      GREEK SMALL LETTER ETA WITH PSILI\n",
      "U+1F21       'ἡ'    3      GREEK SMALL LETTER ETA WITH DASIA\n"
     ]
    }
   ],
   "source": [
    "# Display the most common case folding targets\n",
    "print(\"Most common case folding targets:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Codepoint':<12} {'Char':<6} {'Freq':<6} {'Name'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for cp, freq in target_frequency.most_common(30):\n",
    "    try:\n",
    "        char = chr(cp)\n",
    "        name = unicodedata.name(char, \"\")\n",
    "    except (ValueError, OverflowError):\n",
    "        char = \"?\"\n",
    "        name = \"\"\n",
    "    print(f\"U+{cp:04X}       {char!r:<6} {freq:<6} {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency distribution (how many targets have N sources folding to them):\n",
      "==================================================\n",
      "Sources folding to target      Count     \n",
      "--------------------------------------------------\n",
      "1                              1379      \n",
      "2                              38        \n",
      "3                              31        \n",
      "4                              2         \n",
      "5                              5         \n",
      "6                              1         \n",
      "8                              1         \n",
      "9                              2         \n",
      "10                             1         \n",
      "11                             1         \n",
      "71                             1         \n",
      "\n",
      "Most characters are targeted by just 1 source (uppercase → lowercase)\n",
      "Characters with freq > 1 have multiple sources folding to them\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of target frequencies\n",
    "freq_distribution = Counter(target_frequency.values())\n",
    "\n",
    "print(\"\\nFrequency distribution (how many targets have N sources folding to them):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Sources folding to target':<30} {'Count':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for n_sources, count in sorted(freq_distribution.items()):\n",
    "    print(f\"{n_sources:<30} {count:<10}\")\n",
    "\n",
    "print(f\"\\nMost characters are targeted by just 1 source (uppercase → lowercase)\")\n",
    "print(f\"Characters with freq > 1 have multiple sources folding to them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters with multiple sources folding to them:\n",
      "================================================================================\n",
      "Target       Char   Freq   Sources folding to this target\n",
      "--------------------------------------------------------------------------------\n",
      "U+03B9       'ι'    71     U+0345 (ͅ), U+0390 (ΐ), U+0399 (Ι), U+1F80 (ᾀ), U+1F81 (ᾁ), ... (+66 more)\n",
      "U+0342       '͂'    11     U+1F56 (ὖ), U+1FB6 (ᾶ), U+1FB7 (ᾷ), U+1FC6 (ῆ), U+1FC7 (ῇ), ... (+6 more)\n",
      "U+03C5       'υ'    10     U+03A5 (Υ), U+03B0 (ΰ), U+1F50 (ὐ), U+1F52 (ὒ), U+1F54 (ὔ), ... (+5 more)\n",
      "U+0066       'f'    9      U+0046 (F), U+FB00 (ﬀ), U+FB01 (ﬁ), U+FB02 (ﬂ), U+FB03 (ﬃ), ... (+1 more)\n",
      "U+0308       '̈'    9      U+0390 (ΐ), U+03B0 (ΰ), U+1E97 (ẗ), U+1FD2 (ῒ), U+1FD3 (ΐ), ... (+4 more)\n",
      "U+0073       's'    8      U+0053 (S), U+00DF (ß), U+017F (ſ), U+1E9E (ẞ), U+FB05 (ﬅ), ... (+1 more)\n",
      "U+03C9       'ω'    6      U+03A9 (Ω), U+1FF3 (ῳ), U+1FF6 (ῶ), U+1FF7 (ῷ), U+1FFC (ῼ), ... (+1 more)\n",
      "U+0301       '́'    5      U+0390 (ΐ), U+03B0 (ΰ), U+1F54 (ὔ), U+1FD3 (ΐ), U+1FE3 (ΰ)\n",
      "U+0313       '̓'    5      U+1F50 (ὐ), U+1F52 (ὒ), U+1F54 (ὔ), U+1F56 (ὖ), U+1FE4 (ῤ)\n",
      "U+03B1       'α'    5      U+0391 (Α), U+1FB3 (ᾳ), U+1FB6 (ᾶ), U+1FB7 (ᾷ), U+1FBC (ᾼ)\n",
      "U+03B7       'η'    5      U+0397 (Η), U+1FC3 (ῃ), U+1FC6 (ῆ), U+1FC7 (ῇ), U+1FCC (ῌ)\n",
      "U+0574       'մ'    5      U+0544 (Մ), U+FB13 (ﬓ), U+FB14 (ﬔ), U+FB15 (ﬕ), U+FB17 (ﬗ)\n",
      "U+0069       'i'    4      U+0049 (I), U+0130 (İ), U+FB01 (ﬁ), U+FB03 (ﬃ)\n",
      "U+0074       't'    4      U+0054 (T), U+1E97 (ẗ), U+FB05 (ﬅ), U+FB06 (ﬆ)\n",
      "U+006C       'l'    3      U+004C (L), U+FB02 (ﬂ), U+FB04 (ﬄ)\n",
      "U+0300       '̀'    3      U+1F52 (ὒ), U+1FD2 (ῒ), U+1FE2 (ῢ)\n",
      "U+03B8       'θ'    3      U+0398 (Θ), U+03D1 (ϑ), U+03F4 (ϴ)\n",
      "U+03C1       'ρ'    3      U+03A1 (Ρ), U+03F1 (ϱ), U+1FE4 (ῤ)\n",
      "U+0442       'т'    3      U+0422 (Т), U+1C84 (ᲄ), U+1C85 (ᲅ)\n",
      "U+0565       'ե'    3      U+0535 (Ե), U+0587 (և), U+FB14 (ﬔ)\n",
      "U+0576       'ն'    3      U+0546 (Ն), U+FB13 (ﬓ), U+FB16 (ﬖ)\n",
      "U+1F00       'ἀ'    3      U+1F08 (Ἀ), U+1F80 (ᾀ), U+1F88 (ᾈ)\n",
      "U+1F01       'ἁ'    3      U+1F09 (Ἁ), U+1F81 (ᾁ), U+1F89 (ᾉ)\n",
      "U+1F02       'ἂ'    3      U+1F0A (Ἂ), U+1F82 (ᾂ), U+1F8A (ᾊ)\n",
      "U+1F03       'ἃ'    3      U+1F0B (Ἃ), U+1F83 (ᾃ), U+1F8B (ᾋ)\n"
     ]
    }
   ],
   "source": [
    "# Show characters with multiple sources folding to them (most interesting cases)\n",
    "print(\"Characters with multiple sources folding to them:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "multi_source_targets = [(cp, freq) for cp, freq in target_frequency.items() if freq > 1]\n",
    "multi_source_targets.sort(key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "print(f\"{'Target':<12} {'Char':<6} {'Freq':<6} {'Sources folding to this target'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for cp, freq in multi_source_targets[:25]:\n",
    "    try:\n",
    "        char = chr(cp)\n",
    "    except (ValueError, OverflowError):\n",
    "        char = \"?\"\n",
    "    \n",
    "    # Find all sources that fold to this target\n",
    "    sources = []\n",
    "    for src_cp, tgt_cps in case_folds.items():\n",
    "        if cp in tgt_cps:\n",
    "            try:\n",
    "                sources.append(f\"U+{src_cp:04X} ({chr(src_cp)})\")\n",
    "            except (ValueError, OverflowError):\n",
    "                sources.append(f\"U+{src_cp:04X}\")\n",
    "    \n",
    "    sources_str = \", \".join(sources[:5])\n",
    "    if len(sources) > 5:\n",
    "        sources_str += f\", ... (+{len(sources)-5} more)\"\n",
    "    \n",
    "    print(f\"U+{cp:04X}       {char!r:<6} {freq:<6} {sources_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case folding expansions (1 char → multiple chars): 104\n",
      "======================================================================\n",
      "Source       Char   Expands to\n",
      "----------------------------------------------------------------------\n",
      "U+00DF       'ß'    'ss' (U+0073 U+0073)\n",
      "U+0130       'İ'    'i̇' (U+0069 U+0307)\n",
      "U+0149       'ŉ'    'ʼn' (U+02BC U+006E)\n",
      "U+01F0       'ǰ'    'ǰ' (U+006A U+030C)\n",
      "U+0390       'ΐ'    'ΐ' (U+03B9 U+0308 U+0301)\n",
      "U+03B0       'ΰ'    'ΰ' (U+03C5 U+0308 U+0301)\n",
      "U+0587       'և'    'եւ' (U+0565 U+0582)\n",
      "U+1E96       'ẖ'    'ẖ' (U+0068 U+0331)\n",
      "U+1E97       'ẗ'    'ẗ' (U+0074 U+0308)\n",
      "U+1E98       'ẘ'    'ẘ' (U+0077 U+030A)\n",
      "U+1E99       'ẙ'    'ẙ' (U+0079 U+030A)\n",
      "U+1E9A       'ẚ'    'aʾ' (U+0061 U+02BE)\n",
      "U+1E9E       'ẞ'    'ss' (U+0073 U+0073)\n",
      "U+1F50       'ὐ'    'ὐ' (U+03C5 U+0313)\n",
      "U+1F52       'ὒ'    'ὒ' (U+03C5 U+0313 U+0300)\n",
      "U+1F54       'ὔ'    'ὔ' (U+03C5 U+0313 U+0301)\n",
      "U+1F56       'ὖ'    'ὖ' (U+03C5 U+0313 U+0342)\n",
      "U+1F80       'ᾀ'    'ἀι' (U+1F00 U+03B9)\n",
      "U+1F81       'ᾁ'    'ἁι' (U+1F01 U+03B9)\n",
      "U+1F82       'ᾂ'    'ἂι' (U+1F02 U+03B9)\n"
     ]
    }
   ],
   "source": [
    "# Analyze expansions (one character folding to multiple characters)\n",
    "expansions = {src: tgt for src, tgt in case_folds.items() if len(tgt) > 1}\n",
    "\n",
    "print(f\"Case folding expansions (1 char → multiple chars): {len(expansions)}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Source':<12} {'Char':<6} {'Expands to'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for src_cp, tgt_cps in list(expansions.items())[:20]:\n",
    "    try:\n",
    "        src_char = chr(src_cp)\n",
    "        tgt_str = \"\".join(chr(cp) for cp in tgt_cps)\n",
    "        tgt_cps_str = \" \".join(f\"U+{cp:04X}\" for cp in tgt_cps)\n",
    "    except (ValueError, OverflowError):\n",
    "        src_char = \"?\"\n",
    "        tgt_str = \"?\"\n",
    "        tgt_cps_str = \"\"\n",
    "    \n",
    "    print(f\"U+{src_cp:04X}       {src_char!r:<6} {tgt_str!r} ({tgt_cps_str})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalization Analysis (All 4 Forms)\n",
    "\n",
    "Unicode defines 4 normalization forms:\n",
    "- **NFC** (Canonical Composition) - most common for text interchange\n",
    "- **NFD** (Canonical Decomposition) - fully decomposed canonical form\n",
    "- **NFKC** (Compatibility Composition) - compatibility + canonical composition\n",
    "- **NFKD** (Compatibility Decomposition) - compatibility + canonical decomposition\n",
    "\n",
    "Characters have Quick_Check properties indicating if they're already normalized:\n",
    "- `Y` (Yes) - definitely normalized\n",
    "- `N` (No) - definitely not normalized\n",
    "- `M` (Maybe) - need to check context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Unicode 17.0.0 DerivedNormalizationProps.txt from https://www.unicode.org/Public/17.0.0/ucd/DerivedNormalizationProps.txt...\n",
      "Cached to /tmp/DerivedNormalizationProps-17.0.0.txt\n",
      "Characters with normalization properties: 22,417\n"
     ]
    }
   ],
   "source": [
    "# Load normalization properties\n",
    "norm_props = get_normalization_props(UNICODE_VERSION)\n",
    "print(f\"Characters with normalization properties: {len(norm_props):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick_Check property distribution:\n",
      "============================================================\n",
      "\n",
      "NFC_QC:\n",
      "  M: 132 characters\n",
      "  N: 1,120 characters\n",
      "\n",
      "NFD_QC:\n",
      "  N: 13,253 characters\n",
      "\n",
      "NFKC_QC:\n",
      "  M: 132 characters\n",
      "  N: 4,965 characters\n",
      "\n",
      "NFKD_QC:\n",
      "  N: 17,086 characters\n"
     ]
    }
   ],
   "source": [
    "# Analyze Quick_Check properties\n",
    "qc_forms = ['NFC_QC', 'NFD_QC', 'NFKC_QC', 'NFKD_QC']\n",
    "\n",
    "print(\"Quick_Check property distribution:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for form in qc_forms:\n",
    "    values = Counter()\n",
    "    for cp, props in norm_props.items():\n",
    "        if form in props:\n",
    "            values[props[form]] += 1\n",
    "    \n",
    "    print(f\"\\n{form}:\")\n",
    "    for val, count in sorted(values.items()):\n",
    "        print(f\"  {val}: {count:,} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters unstable under each normalization form:\n",
      "==================================================\n",
      "NFC_QC: 1,252 characters\n",
      "NFD_QC: 13,253 characters\n",
      "NFKC_QC: 5,097 characters\n",
      "NFKD_QC: 17,086 characters\n",
      "\n",
      "Unstable under ANY form: 17,206 characters\n"
     ]
    }
   ],
   "source": [
    "# Find characters that are NOT stable under each normalization form\n",
    "unstable = {form: set() for form in qc_forms}\n",
    "\n",
    "for cp, props in norm_props.items():\n",
    "    for form in qc_forms:\n",
    "        if form in props and props[form] != 'Y':\n",
    "            unstable[form].add(cp)\n",
    "\n",
    "print(\"Characters unstable under each normalization form:\")\n",
    "print(\"=\" * 50)\n",
    "for form in qc_forms:\n",
    "    print(f\"{form}: {len(unstable[form]):,} characters\")\n",
    "\n",
    "# Characters unstable under ANY form\n",
    "unstable_any = set()\n",
    "for s in unstable.values():\n",
    "    unstable_any.update(s)\n",
    "print(f\"\\nUnstable under ANY form: {len(unstable_any):,} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of normalization-unstable characters:\n",
      "================================================================================\n",
      "Codepoint    Char   NFC    NFD    NFKC   NFKD   Name\n",
      "--------------------------------------------------------------------------------\n",
      "U+00A0       '\\xa0' Y      Y      N      N      NO-BREAK SPACE\n",
      "U+00A8       '¨'    Y      Y      N      N      DIAERESIS\n",
      "U+00AA       'ª'    Y      Y      N      N      FEMININE ORDINAL INDICATOR\n",
      "U+00AF       '¯'    Y      Y      N      N      MACRON\n",
      "U+00B2       '²'    Y      Y      N      N      SUPERSCRIPT TWO\n",
      "U+00B3       '³'    Y      Y      N      N      SUPERSCRIPT THREE\n",
      "U+00B4       '´'    Y      Y      N      N      ACUTE ACCENT\n",
      "U+00B5       'µ'    Y      Y      N      N      MICRO SIGN\n",
      "U+00B8       '¸'    Y      Y      N      N      CEDILLA\n",
      "U+00B9       '¹'    Y      Y      N      N      SUPERSCRIPT ONE\n",
      "U+00BA       'º'    Y      Y      N      N      MASCULINE ORDINAL INDICATOR\n",
      "U+00BC       '¼'    Y      Y      N      N      VULGAR FRACTION ONE QUARTER\n",
      "U+00BD       '½'    Y      Y      N      N      VULGAR FRACTION ONE HALF\n",
      "U+00BE       '¾'    Y      Y      N      N      VULGAR FRACTION THREE QUARTERS\n",
      "U+00C0       'À'    Y      N      Y      N      LATIN CAPITAL LETTER A WITH GR\n",
      "U+00C1       'Á'    Y      N      Y      N      LATIN CAPITAL LETTER A WITH AC\n",
      "U+00C2       'Â'    Y      N      Y      N      LATIN CAPITAL LETTER A WITH CI\n",
      "U+00C3       'Ã'    Y      N      Y      N      LATIN CAPITAL LETTER A WITH TI\n",
      "U+00C4       'Ä'    Y      N      Y      N      LATIN CAPITAL LETTER A WITH DI\n",
      "U+00C5       'Å'    Y      N      Y      N      LATIN CAPITAL LETTER A WITH RI\n",
      "U+00C7       'Ç'    Y      N      Y      N      LATIN CAPITAL LETTER C WITH CE\n",
      "U+00C8       'È'    Y      N      Y      N      LATIN CAPITAL LETTER E WITH GR\n",
      "U+00C9       'É'    Y      N      Y      N      LATIN CAPITAL LETTER E WITH AC\n",
      "U+00CA       'Ê'    Y      N      Y      N      LATIN CAPITAL LETTER E WITH CI\n",
      "U+00CB       'Ë'    Y      N      Y      N      LATIN CAPITAL LETTER E WITH DI\n"
     ]
    }
   ],
   "source": [
    "# Show some examples of unstable characters\n",
    "print(\"Examples of normalization-unstable characters:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Codepoint':<12} {'Char':<6} {'NFC':<6} {'NFD':<6} {'NFKC':<6} {'NFKD':<6} {'Name'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "shown = 0\n",
    "for cp in sorted(unstable_any):\n",
    "    if shown >= 25:\n",
    "        break\n",
    "    props = norm_props.get(cp, {})\n",
    "    try:\n",
    "        char = chr(cp)\n",
    "        name = unicodedata.name(char, \"\")[:30]\n",
    "    except (ValueError, OverflowError):\n",
    "        char = \"?\"\n",
    "        name = \"\"\n",
    "    \n",
    "    nfc = props.get('NFC_QC', 'Y')\n",
    "    nfd = props.get('NFD_QC', 'Y')\n",
    "    nfkc = props.get('NFKC_QC', 'Y')\n",
    "    nfkd = props.get('NFKD_QC', 'Y')\n",
    "    \n",
    "    print(f\"U+{cp:04X}       {char!r:<6} {nfc:<6} {nfd:<6} {nfkc:<6} {nfkd:<6} {name}\")\n",
    "    shown += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anchor Point Analysis for Search\n",
    "\n",
    "Now we identify characters that make good \"anchor points\" for search algorithms.\n",
    "A good anchor point should:\n",
    "1. Not change under case folding\n",
    "2. Not change under normalization (all 4 forms)\n",
    "3. Not be a target of many other characters' transformations\n",
    "4. Have good UTF-8 byte properties for SIMD matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached Unicode 17.0.0 UCD XML: /tmp/ucd-17.0.0.all.flat.xml\n",
      "Total codepoints in Unicode 17.0.0: 159,866\n"
     ]
    }
   ],
   "source": [
    "# Load all characters from XML for comprehensive analysis\n",
    "root = get_unicode_xml_data(UNICODE_VERSION)\n",
    "chars = [elem for elem in root.iter() if elem.tag.endswith('char')]\n",
    "\n",
    "all_codepoints = set()\n",
    "char_info = {}  # cp -> {name, gc, ...}\n",
    "\n",
    "for elem in chars:\n",
    "    if 'cp' in elem.attrib:\n",
    "        cp = int(elem.attrib['cp'], 16)\n",
    "        all_codepoints.add(cp)\n",
    "        char_info[cp] = {\n",
    "            'name': elem.attrib.get('na', '').strip(),\n",
    "            'gc': elem.attrib.get('gc', '').strip(),\n",
    "        }\n",
    "\n",
    "print(f\"Total codepoints in Unicode {UNICODE_VERSION}: {len(all_codepoints):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anchor_score(cp: int) -> dict:\n",
    "    \"\"\"\n",
    "    Compute an anchor point score for a codepoint.\n",
    "    Returns a dict with component scores and total score.\n",
    "    Higher score = better anchor point.\n",
    "    \"\"\"\n",
    "    score = {\n",
    "        'case_fold_stable': 0,     # Does not change under case folding\n",
    "        'case_fold_target': 0,     # Not targeted by other characters\n",
    "        'norm_stable': 0,          # Stable under all normalization forms\n",
    "        'not_combining': 0,        # Not a combining mark\n",
    "        'byte_entropy': 0,         # Good UTF-8 byte properties\n",
    "        'total': 0\n",
    "    }\n",
    "    \n",
    "    # Case folding stability: +2 if not in fold table (maps to itself)\n",
    "    if cp not in case_folds:\n",
    "        score['case_fold_stable'] = 2\n",
    "    \n",
    "    # Case folding target: +2 if not targeted, -1 per additional source\n",
    "    if cp not in target_frequency:\n",
    "        score['case_fold_target'] = 2\n",
    "    else:\n",
    "        freq = target_frequency[cp]\n",
    "        score['case_fold_target'] = max(-2, 1 - freq)  # Penalize heavily-targeted chars\n",
    "    \n",
    "    # Normalization stability: +1 for each stable form, +2 bonus if all stable\n",
    "    props = norm_props.get(cp, {})\n",
    "    stable_count = 0\n",
    "    for form in qc_forms:\n",
    "        if props.get(form, 'Y') == 'Y':\n",
    "            stable_count += 1\n",
    "    score['norm_stable'] = stable_count\n",
    "    if stable_count == 4:\n",
    "        score['norm_stable'] += 2  # Bonus for fully stable\n",
    "    \n",
    "    # Not combining mark: +2 if not a combining mark (gc != Mn, Mc, Me)\n",
    "    info = char_info.get(cp, {})\n",
    "    gc = info.get('gc', '')\n",
    "    if gc not in ('Mn', 'Mc', 'Me'):\n",
    "        score['not_combining'] = 2\n",
    "    \n",
    "    # UTF-8 byte entropy\n",
    "    # ASCII (0-127): highest entropy, single byte, +3\n",
    "    # 2-byte sequences (128-2047): continuation bytes are diverse, +2\n",
    "    # 3-byte sequences: lead byte has fewer info bits, +1\n",
    "    # 4-byte sequences: lead byte has only 3 info bits, +0\n",
    "    if cp < 128:\n",
    "        score['byte_entropy'] = 3\n",
    "    elif cp < 2048:\n",
    "        score['byte_entropy'] = 2\n",
    "    elif cp < 65536:\n",
    "        score['byte_entropy'] = 1\n",
    "    else:\n",
    "        score['byte_entropy'] = 0\n",
    "    \n",
    "    score['total'] = sum(v for k, v in score.items() if k != 'total')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed anchor scores for 159,866 codepoints\n",
      "\n",
      "Score distribution:\n",
      "  Score 15: 76 characters\n",
      "  Score 14: 622 characters\n",
      "  Score 13: 37,174 characters\n",
      "  Score 12: 101,127 characters\n",
      "  Score 11: 1,896 characters\n",
      "  Score 10: 1,813 characters\n",
      "  Score 9: 13,511 characters\n",
      "  Score 8: 1,829 characters\n",
      "  Score 7: 1,150 characters\n",
      "  Score 6: 596 characters\n"
     ]
    }
   ],
   "source": [
    "# Compute anchor scores for all codepoints\n",
    "anchor_scores = {}\n",
    "for cp in all_codepoints:\n",
    "    anchor_scores[cp] = compute_anchor_score(cp)\n",
    "\n",
    "# Sort by total score descending\n",
    "sorted_anchors = sorted(anchor_scores.items(), key=lambda x: -x[1]['total'])\n",
    "\n",
    "print(f\"Computed anchor scores for {len(anchor_scores):,} codepoints\")\n",
    "print(f\"\\nScore distribution:\")\n",
    "score_dist = Counter(s['total'] for s in anchor_scores.values())\n",
    "for score, count in sorted(score_dist.items(), reverse=True)[:10]:\n",
    "    print(f\"  Score {score}: {count:,} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best anchor points for search:\n",
      "==========================================================================================\n",
      "CP         Char   Total  Fold  Tgt   Norm  Comb  Byte  Name\n",
      "------------------------------------------------------------------------------------------\n",
      "U+0000    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0001    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0002    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0003    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0004    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0005    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0006    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0007    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0008    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0009    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+000A    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+000B    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+000C    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+000D    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+000E    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+000F    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0010    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0011    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0012    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0013    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0014    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0015    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0016    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0017    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0018    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0019    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+001A    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+001B    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+001C    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+001D    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+001E    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+001F    '·'    15     2     2     6     2     3     MIDDLE DOT\n",
      "U+0020    ' '    15     2     2     6     2     3     SPACE\n",
      "U+0021    '!'    15     2     2     6     2     3     EXCLAMATION MARK\n",
      "U+0022    '\"'    15     2     2     6     2     3     QUOTATION MARK\n",
      "U+0023    '#'    15     2     2     6     2     3     NUMBER SIGN\n",
      "U+0024    '$'    15     2     2     6     2     3     DOLLAR SIGN\n",
      "U+0025    '%'    15     2     2     6     2     3     PERCENT SIGN\n",
      "U+0026    '&'    15     2     2     6     2     3     AMPERSAND\n",
      "U+0027    \"'\"    15     2     2     6     2     3     APOSTROPHE\n",
      "U+0028    '('    15     2     2     6     2     3     LEFT PARENTHESIS\n",
      "U+0029    ')'    15     2     2     6     2     3     RIGHT PARENTHESIS\n",
      "U+002A    '*'    15     2     2     6     2     3     ASTERISK\n",
      "U+002B    '+'    15     2     2     6     2     3     PLUS SIGN\n",
      "U+002C    ','    15     2     2     6     2     3     COMMA\n",
      "U+002D    '-'    15     2     2     6     2     3     HYPHEN-MINUS\n",
      "U+002E    '.'    15     2     2     6     2     3     FULL STOP\n",
      "U+002F    '/'    15     2     2     6     2     3     SOLIDUS\n",
      "U+0030    '0'    15     2     2     6     2     3     DIGIT ZERO\n",
      "U+0031    '1'    15     2     2     6     2     3     DIGIT ONE\n"
     ]
    }
   ],
   "source": [
    "# Display best anchor points\n",
    "print(\"Best anchor points for search:\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'CP':<10} {'Char':<6} {'Total':<6} {'Fold':<5} {'Tgt':<5} {'Norm':<5} {'Comb':<5} {'Byte':<5} {'Name'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for cp, scores in sorted_anchors[:50]:\n",
    "    try:\n",
    "        char = chr(cp)\n",
    "        # Skip control characters for display\n",
    "        if unicodedata.category(char) in ('Cc', 'Cf', 'Cs', 'Co', 'Cn'):\n",
    "            char = '·'\n",
    "        name = unicodedata.name(char, char_info.get(cp, {}).get('name', ''))[:25]\n",
    "    except (ValueError, OverflowError):\n",
    "        char = \"?\"\n",
    "        name = \"\"\n",
    "    \n",
    "    print(f\"U+{cp:04X}    {char!r:<6} {scores['total']:<6} \"\n",
    "          f\"{scores['case_fold_stable']:<5} {scores['case_fold_target']:<5} \"\n",
    "          f\"{scores['norm_stable']:<5} {scores['not_combining']:<5} \"\n",
    "          f\"{scores['byte_entropy']:<5} {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCII Anchor Analysis (printable characters):\n",
      "================================================================================\n",
      "Char   Score  Fold  Tgt   Notes\n",
      "--------------------------------------------------------------------------------\n",
      "' '    15     2     2     STABLE - good anchor\n",
      "'!'    15     2     2     STABLE - good anchor\n",
      "'\"'    15     2     2     STABLE - good anchor\n",
      "'#'    15     2     2     STABLE - good anchor\n",
      "'$'    15     2     2     STABLE - good anchor\n",
      "'%'    15     2     2     STABLE - good anchor\n",
      "'&'    15     2     2     STABLE - good anchor\n",
      "\"'\"    15     2     2     STABLE - good anchor\n",
      "'('    15     2     2     STABLE - good anchor\n",
      "')'    15     2     2     STABLE - good anchor\n",
      "'*'    15     2     2     STABLE - good anchor\n",
      "'+'    15     2     2     STABLE - good anchor\n",
      "','    15     2     2     STABLE - good anchor\n",
      "'-'    15     2     2     STABLE - good anchor\n",
      "'.'    15     2     2     STABLE - good anchor\n",
      "'/'    15     2     2     STABLE - good anchor\n",
      "'0'    15     2     2     STABLE - good anchor\n",
      "'1'    15     2     2     STABLE - good anchor\n",
      "'2'    15     2     2     STABLE - good anchor\n",
      "'3'    15     2     2     STABLE - good anchor\n",
      "'4'    15     2     2     STABLE - good anchor\n",
      "'5'    15     2     2     STABLE - good anchor\n",
      "'6'    15     2     2     STABLE - good anchor\n",
      "'7'    15     2     2     STABLE - good anchor\n",
      "'8'    15     2     2     STABLE - good anchor\n",
      "'9'    15     2     2     STABLE - good anchor\n",
      "':'    15     2     2     STABLE - good anchor\n",
      "';'    15     2     2     STABLE - good anchor\n",
      "'<'    15     2     2     STABLE - good anchor\n",
      "'='    15     2     2     STABLE - good anchor\n",
      "'>'    15     2     2     STABLE - good anchor\n",
      "'?'    15     2     2     STABLE - good anchor\n",
      "'@'    15     2     2     STABLE - good anchor\n",
      "'A'    13     0     2     folds to a\n",
      "'B'    13     0     2     folds to b\n",
      "'C'    13     0     2     folds to c\n",
      "'D'    13     0     2     folds to d\n",
      "'E'    13     0     2     folds to e\n",
      "'F'    13     0     2     folds to f\n",
      "'G'    13     0     2     folds to g\n",
      "'H'    13     0     2     folds to h\n",
      "'I'    13     0     2     folds to i\n",
      "'J'    13     0     2     folds to j\n",
      "'K'    13     0     2     folds to k\n",
      "'L'    13     0     2     folds to l\n",
      "'M'    13     0     2     folds to m\n",
      "'N'    13     0     2     folds to n\n",
      "'O'    13     0     2     folds to o\n",
      "'P'    13     0     2     folds to p\n",
      "'Q'    13     0     2     folds to q\n",
      "'R'    13     0     2     folds to r\n",
      "'S'    13     0     2     folds to s\n",
      "'T'    13     0     2     folds to t\n",
      "'U'    13     0     2     folds to u\n",
      "'V'    13     0     2     folds to v\n",
      "'W'    13     0     2     folds to w\n",
      "'X'    13     0     2     folds to x\n",
      "'Y'    13     0     2     folds to y\n",
      "'Z'    13     0     2     folds to z\n",
      "'['    15     2     2     STABLE - good anchor\n",
      "'\\\\'   15     2     2     STABLE - good anchor\n",
      "']'    15     2     2     STABLE - good anchor\n",
      "'^'    15     2     2     STABLE - good anchor\n",
      "'_'    15     2     2     STABLE - good anchor\n",
      "'`'    15     2     2     STABLE - good anchor\n",
      "'a'    12     2     -1    target of 2 char(s)\n",
      "'b'    13     2     0     target of 1 char(s)\n",
      "'c'    13     2     0     target of 1 char(s)\n",
      "'d'    13     2     0     target of 1 char(s)\n",
      "'e'    13     2     0     target of 1 char(s)\n",
      "'f'    11     2     -2    target of 9 char(s)\n",
      "'g'    13     2     0     target of 1 char(s)\n",
      "'h'    12     2     -1    target of 2 char(s)\n",
      "'i'    11     2     -2    target of 4 char(s)\n",
      "'j'    12     2     -1    target of 2 char(s)\n",
      "'k'    12     2     -1    target of 2 char(s)\n",
      "'l'    11     2     -2    target of 3 char(s)\n",
      "'m'    13     2     0     target of 1 char(s)\n",
      "'n'    12     2     -1    target of 2 char(s)\n",
      "'o'    13     2     0     target of 1 char(s)\n",
      "'p'    13     2     0     target of 1 char(s)\n",
      "'q'    13     2     0     target of 1 char(s)\n",
      "'r'    13     2     0     target of 1 char(s)\n",
      "'s'    11     2     -2    target of 8 char(s)\n",
      "'t'    11     2     -2    target of 4 char(s)\n",
      "'u'    13     2     0     target of 1 char(s)\n",
      "'v'    13     2     0     target of 1 char(s)\n",
      "'w'    12     2     -1    target of 2 char(s)\n",
      "'x'    13     2     0     target of 1 char(s)\n",
      "'y'    12     2     -1    target of 2 char(s)\n",
      "'z'    13     2     0     target of 1 char(s)\n",
      "'{'    15     2     2     STABLE - good anchor\n",
      "'|'    15     2     2     STABLE - good anchor\n",
      "'}'    15     2     2     STABLE - good anchor\n",
      "'~'    15     2     2     STABLE - good anchor\n"
     ]
    }
   ],
   "source": [
    "# Focus on ASCII anchors (most useful for fast paths)\n",
    "print(\"ASCII Anchor Analysis (printable characters):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Char':<6} {'Score':<6} {'Fold':<5} {'Tgt':<5} {'Notes'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for cp in range(32, 127):\n",
    "    if cp not in anchor_scores:\n",
    "        continue\n",
    "    scores = anchor_scores[cp]\n",
    "    char = chr(cp)\n",
    "    \n",
    "    notes = []\n",
    "    if cp in case_folds:\n",
    "        tgt = case_folds[cp]\n",
    "        notes.append(f\"folds to {chr(tgt[0])}\")\n",
    "    if cp in target_frequency:\n",
    "        notes.append(f\"target of {target_frequency[cp]} char(s)\")\n",
    "    \n",
    "    notes_str = \"; \".join(notes) if notes else \"STABLE - good anchor\"\n",
    "    \n",
    "    print(f\"{char!r:<6} {scores['total']:<6} {scores['case_fold_stable']:<5} \"\n",
    "          f\"{scores['case_fold_target']:<5} {notes_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfect ASCII anchors (43 characters):\n",
      "These are ideal for fast-path case-insensitive/normalized search:\n",
      "\n",
      "Digits: 0123456789\n",
      "Lowercase (stable): (none - all have uppercase variants)\n",
      "Uppercase (stable): (none - all fold to lowercase)\n",
      "Punctuation/Symbols:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# Identify perfect ASCII anchors (highest score, no transformations)\n",
    "perfect_ascii_anchors = []\n",
    "for cp in range(32, 127):\n",
    "    if cp not in anchor_scores:\n",
    "        continue\n",
    "    scores = anchor_scores[cp]\n",
    "    # Perfect anchor: not in fold table, not a target, all norm stable\n",
    "    if (scores['case_fold_stable'] == 2 and \n",
    "        scores['case_fold_target'] == 2 and\n",
    "        scores['norm_stable'] >= 6):\n",
    "        perfect_ascii_anchors.append((cp, chr(cp)))\n",
    "\n",
    "print(f\"\\nPerfect ASCII anchors ({len(perfect_ascii_anchors)} characters):\")\n",
    "print(\"These are ideal for fast-path case-insensitive/normalized search:\")\n",
    "print()\n",
    "\n",
    "# Group by category\n",
    "digits = [c for cp, c in perfect_ascii_anchors if c.isdigit()]\n",
    "punct = [c for cp, c in perfect_ascii_anchors if not c.isalnum()]\n",
    "lower = [c for cp, c in perfect_ascii_anchors if c.islower()]\n",
    "upper = [c for cp, c in perfect_ascii_anchors if c.isupper()]\n",
    "\n",
    "print(f\"Digits: {''.join(digits)}\")\n",
    "print(f\"Lowercase (stable): {''.join(lower) if lower else '(none - all have uppercase variants)'}\")\n",
    "print(f\"Uppercase (stable): {''.join(upper) if upper else '(none - all fold to lowercase)'}\")\n",
    "print(f\"Punctuation/Symbols: {''.join(punct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY: Anchor Point Statistics\n",
      "============================================================\n",
      "\n",
      "Maximum possible anchor score: 15\n",
      "Characters with perfect score: 76\n",
      "Characters fully stable (no case/norm transformations): 140,592\n",
      "\n",
      "For search algorithm design:\n",
      "  - Use ASCII digits and punctuation as primary anchors\n",
      "  - Lowercase letters are targets of uppercase folding\n",
      "  - Avoid combining marks (gc=Mn/Mc/Me) as anchors\n",
      "  - Prefer single-byte UTF-8 (ASCII) for SIMD efficiency\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY: Anchor Point Statistics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "max_score = max(s['total'] for s in anchor_scores.values())\n",
    "perfect_anchors = sum(1 for s in anchor_scores.values() if s['total'] == max_score)\n",
    "\n",
    "print(f\"\\nMaximum possible anchor score: {max_score}\")\n",
    "print(f\"Characters with perfect score: {perfect_anchors:,}\")\n",
    "\n",
    "# Characters stable under all conditions\n",
    "fully_stable = sum(1 for s in anchor_scores.values() \n",
    "                   if s['case_fold_stable'] == 2 and \n",
    "                      s['case_fold_target'] == 2 and\n",
    "                      s['norm_stable'] >= 6)\n",
    "print(f\"Characters fully stable (no case/norm transformations): {fully_stable:,}\")\n",
    "\n",
    "print(f\"\\nFor search algorithm design:\")\n",
    "print(f\"  - Use ASCII digits and punctuation as primary anchors\")\n",
    "print(f\"  - Lowercase letters are targets of uppercase folding\")\n",
    "print(f\"  - Avoid combining marks (gc=Mn/Mc/Me) as anchors\")\n",
    "print(f\"  - Prefer single-byte UTF-8 (ASCII) for SIMD efficiency\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StringZilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
